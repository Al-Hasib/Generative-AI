{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Generate 5 quiz questions with four multiple-choice options for each question. Highlight the correct answer.', additional_kwargs={}, response_metadata={}), HumanMessage(content='You have to following the below content to create the quizes\\n                   Content: Tangail', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# model = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n",
    "# Access the API key from the environment\n",
    "api_key = os.getenv(\"GOOGLE_GEN_API\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Generate 5 quiz questions with four multiple-choice options for each question. Highlight the correct answer.', additional_kwargs={}, response_metadata={}), HumanMessage(content='You have to following the below content to create the quizes\\n          Content: Tangail', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "quiz_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Generate {num_questions} quiz questions with four multiple-choice options for each question. Highlight the correct answer.\"),\n",
    "        (\"human\", \"You have to following the below content to create the quizes\\n \\\n",
    "         Content: {text}\"),\n",
    "    ]\n",
    ")\n",
    "print(quiz_prompt.invoke({\"num_questions\": \"5\", \"text\": \"Tangail\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load PDF using LangChain Community Loader\n",
    "def load_pdf(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    return \" \".join([doc.page_content for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain \\n What is LangChain? \\nLangChain is a framework for developing applications powered by large \\nlanguage models (LLMs). LangChain is a framework that enables the \\ncreation of multi-step machine learning pipelines involving LLMs, retrieval \\nsystems, external integrations, and fine-tuning, all within a unified API. \\nLangChain is a product development tool that lets you build interactive, \\nLLM-driven applications, integrating APIs, databases, and external data to \\ncreate end-to-end solutions for complex natural language tasks. It's a \\nwrapper of multiple things to create a end to end solutions. \\n Libraries \\n‚óèLangchain core \\n‚óèLangchain Community \\n‚óèPartners \\n‚óèLangchain \\n‚óèLangGraph \\n‚óèLangServe \\n‚óèLangSmith \\n Features \\n‚óèChat Models \\n‚óèPrompt Templates \\n‚óèChain \\n‚óèRAG (Retrieval Augment \\nGeneration) \\n‚óèAgent & Tools \\n‚óèMemory \\n‚óèDocument Loaders \\n‚óèEmbeddings \\n‚óèVector Stores ‚óèCustom Tools \\n‚óèText Splitting \\n‚óèLangChain Hub \\n‚óèCaching \\n‚óèEvaluation & Tracing \\n‚óèExternal Data Integration \\n‚óèStreaming \\n‚óèMulti Modal Support \\n‚óèCallbacks \\n‚óèOutput Parsers & so on‚Ä¶  Thanks For Watching \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pdf(r\"F:\\Youtube\\Generative AI\\Langchain\\Generative-AI\\LangChain\\Overview of Langchain.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load Text using LangChain Community Loader\n",
    "def load_text(file):\n",
    "    loader = TextLoader(file)\n",
    "    documents = loader.load()\n",
    "    return \" \".join([doc.page_content for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is a popular framework designed to facilitate the development of applications that leverage language models (LLMs). It provides a streamlined way to integrate LLMs with various data sources, APIs, and external tools, enabling complex workflows and making it easier to build advanced AI applications.\\n\\nHere√¢‚Ç¨‚Ñ¢s an overview of its key features:\\n\\n### 1. **Chains**\\n   - Chains allow you to link together multiple components, such as prompts and models, to create more sophisticated workflows.\\n   - You can build sequential chains (step-by-step tasks) or custom chains depending on the application's needs.\\n\\n### 2. **Agents**\\n   - Agents in LangChain are specialized modules that make decisions about which actions to take. They can autonomously call different tools or APIs based on user input.\\n   - An agent could, for example, process a query by interacting with a search engine, perform calculations, or use APIs to retrieve specific data.\\n\\n### 3. **Memory**\\n   - LangChain supports long-term memory, allowing applications to keep track of conversation history or user preferences across multiple interactions.\\n   - This is especially useful for chatbots, where context needs to be maintained over a conversation.\\n\\n### 4. **Retrieval-Augmented Generation (RAG)**\\n   - LangChain helps implement RAG, a process where language models retrieve external knowledge or documents to produce more accurate or contextual responses.\\n   - This is beneficial when creating models that need access to up-to-date information or niche domain knowledge.\\n\\n### 5. **Prompt Templates**\\n   - Prompt templates allow developers to create dynamic and reusable prompts that can be filled with different inputs. This simplifies the process of managing complex prompts across various tasks.\\n   - LangChain offers utilities for chaining these prompts with other components or integrating them into larger workflows.\\n\\n### 6. **Tools Integration**\\n   - LangChain easily integrates with external tools and APIs, enabling the LLM to extend its capabilities, such as performing searches, accessing databases, or interacting with APIs.\\n   - You can also build custom tools for specific use cases.\\n\\n### 7. **Streaming Output**\\n   - LangChain supports streaming responses, useful for tasks where immediate feedback or gradual responses are required, such as when interacting with large datasets or making real-time decisions.\\n\\n### 8. **Ecosystem Support**\\n   - It has built-in integrations with various LLM providers like OpenAI, Hugging Face, Cohere, and others. It also supports vector databases like Pinecone, Weaviate, and FAISS for retrieving relevant information during query processing.\\n\\n### Use Cases\\n   - **Chatbots and Conversational Agents**: Memory, agents, and chains allow for context-aware chatbots.\\n   - **Document Q&A Systems**: Using RAG, LangChain can retrieve relevant documents for answering specific questions.\\n   - **Data-Driven Applications**: Integration with APIs, databases, and retrieval mechanisms enables building apps that provide real-time data-backed responses.\\n\\nLangChain has a modular architecture, making it flexible and customizable depending on the application. It√¢‚Ç¨‚Ñ¢s highly suited for building AI-driven systems that need to integrate LLMs with structured data sources, workflows, or external tools.\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_text(Path(\"F:\\Youtube\\Generative AI\\Langchain\\ChatModels\\data\\sample.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Skip to main content](#__docusaurus_skipToContent_fallback)\\n\\n[![ü¶úÔ∏èüîó LangChain](https://python.langchain.com/img/brand/wordmark.png)](/)[Integrations](/docs/integrations/platforms/) [API Reference](https://python.langchain.com/api_reference/)\\n\\nMore\\n\\n- [Contributing](/docs/contributing/)\\n- [People](/docs/people/)\\n- * * *\\n\\n- [LangSmith](https://docs.smith.langchain.com)\\n- [LangGraph](https://langchain-ai.github.io/langgraph/)\\n- [LangChain Hub](https://smith.langchain.com/hub)\\n- [LangChain JS/TS](https://js.langchain.com)\\n\\nv0.3\\n\\n- [v0.3](/docs/introduction/)\\n- [v0.2](https://python.langchain.com/v0.2/docs/introduction)\\n- [v0.1](https://python.langchain.com/v0.1/docs/get_started/introduction)\\n\\n[üí¨](https://chat.langchain.com)  [GitHub repository](https://github.com/langchain-ai/langchain)\\n\\nSearch`` `K`\\n\\n- [Introduction](/docs/introduction/)\\n- [Tutorials](/docs/tutorials/)\\n\\n  - [Build a Question Answering application over a Graph Database](/docs/tutorials/graph/)\\n  - [Tutorials](/docs/tutorials/)\\n  - [Build a Simple LLM Application with LCEL](/docs/tutorials/llm_chain/)\\n  - [Build a Query Analysis System](/docs/tutorials/query_analysis/)\\n  - [Build a Chatbot](/docs/tutorials/chatbot/)\\n  - [Conversational RAG](/docs/tutorials/qa_chat_history/)\\n  - [Build an Extraction Chain](/docs/tutorials/extraction/)\\n  - [Build an Agent](/docs/tutorials/agents/)\\n  - [Tagging](/docs/tutorials/classification/)\\n  - [data\\\\_generation](/docs/tutorials/data_generation/)\\n  - [Build a Local RAG Application](/docs/tutorials/local_rag/)\\n  - [Build a PDF ingestion and Question/Answering system](/docs/tutorials/pdf_qa/)\\n  - [Build a Retrieval Augmented Generation (RAG) App](/docs/tutorials/rag/)\\n  - [Vector stores and retrievers](/docs/tutorials/retrievers/)\\n  - [Build a Question/Answering system over SQL data](/docs/tutorials/sql_qa/)\\n  - [Summarize Text](/docs/tutorials/summarization/)\\n- [How-to guides](/docs/how_to/)\\n\\n  - [How-to guides](/docs/how_to/)\\n  - [How to use tools in a chain](/docs/how_to/tools_chain/)\\n  - [How to use a vectorstore as a retriever](/docs/how_to/vectorstore_retriever/)\\n  - [How to add memory to chatbots](/docs/how_to/chatbots_memory/)\\n  - [How to use example selectors](/docs/how_to/example_selectors/)\\n  - [How to map values to a graph database](/docs/how_to/graph_mapping/)\\n  - [How to add a semantic layer over graph database](/docs/how_to/graph_semantic/)\\n  - [How to invoke runnables in parallel](/docs/how_to/parallel/)\\n  - [How to stream chat model responses](/docs/how_to/chat_streaming/)\\n  - [How to add default invocation args to a Runnable](/docs/how_to/binding/)\\n  - [How to add retrieval to chatbots](/docs/how_to/chatbots_retrieval/)\\n  - [How to use few shot examples in chat models](/docs/how_to/few_shot_examples_chat/)\\n  - [How to do tool/function calling](/docs/how_to/function_calling/)\\n  - [How to best prompt for Graph-RAG](/docs/how_to/graph_prompting/)\\n  - [How to install LangChain packages](/docs/how_to/installation/)\\n  - [How to add examples to the prompt for query analysis](/docs/how_to/query_few_shot/)\\n  - [How to use few shot examples](/docs/how_to/few_shot_examples/)\\n  - [How to run custom functions](/docs/how_to/functions/)\\n  - [How to use output parsers to parse an LLM response into structured format](/docs/how_to/output_parser_structured/)\\n  - [How to handle cases where no queries are generated](/docs/how_to/query_no_queries/)\\n  - [How to route between sub-chains](/docs/how_to/routing/)\\n  - [How to return structured data from a model](/docs/how_to/structured_output/)\\n  - [How to summarize text through parallelization](/docs/how_to/summarize_map_reduce/)\\n  - [How to summarize text through iterative refinement](/docs/how_to/summarize_refine/)\\n  - [How to summarize text in a single LLM call](/docs/how_to/summarize_stuff/)\\n  - [How to use toolkits](/docs/how_to/toolkits/)\\n  - [How to add ad-hoc tool calling capability to LLMs and Chat Models](/docs/how_to/tools_prompting/)\\n  - [Build an Agent with AgentExecutor (Legacy)](/docs/how_to/agent_executor/)\\n  - [How to construct knowledge graphs](/docs/how_to/graph_constructing/)\\n  - [How to partially format prompt templates](/docs/how_to/prompts_partial/)\\n  - [How to handle multiple queries when doing query analysis](/docs/how_to/query_multiple_queries/)\\n  - [How to use built-in tools and toolkits](/docs/how_to/tools_builtin/)\\n  - [How to pass through arguments from one step to the next](/docs/how_to/passthrough/)\\n  - [How to compose prompts together](/docs/how_to/prompts_composition/)\\n  - [How to handle multiple retrievers when doing query analysis](/docs/how_to/query_multiple_retrievers/)\\n  - [How to add values to a chain\\'s state](/docs/how_to/assign/)\\n  - [How to construct filters for query analysis](/docs/how_to/query_constructing_filters/)\\n  - [How to configure runtime chain internals](/docs/how_to/configure/)\\n  - [How deal with high cardinality categoricals when doing query analysis](/docs/how_to/query_high_cardinality/)\\n  - [Custom Document Loader](/docs/how_to/document_loader_custom/)\\n  - [How to split by HTML header](/docs/how_to/HTML_header_metadata_splitter/)\\n  - [How to split by HTML sections](/docs/how_to/HTML_section_aware_splitter/)\\n  - [How to use the MultiQueryRetriever](/docs/how_to/MultiQueryRetriever/)\\n  - [How to add scores to retriever results](/docs/how_to/add_scores_retriever/)\\n  - [Caching](/docs/how_to/caching_embeddings/)\\n  - [How to use callbacks in async environments](/docs/how_to/callbacks_async/)\\n  - [How to attach callbacks to a runnable](/docs/how_to/callbacks_attach/)\\n  - [How to propagate callbacks constructor](/docs/how_to/callbacks_constructor/)\\n  - [How to dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\\n  - [How to pass callbacks in at runtime](/docs/how_to/callbacks_runtime/)\\n  - [How to split by character](/docs/how_to/character_text_splitter/)\\n  - [How to cache chat model responses](/docs/how_to/chat_model_caching/)\\n  - [How to handle rate limits](/docs/how_to/chat_model_rate_limiting/)\\n  - [How to init any model in one line](/docs/how_to/chat_models_universal_init/)\\n  - [How to track token usage in ChatModels](/docs/how_to/chat_token_usage_tracking/)\\n  - [How to add tools to chatbots](/docs/how_to/chatbots_tools/)\\n  - [How to split code](/docs/how_to/code_splitter/)\\n  - [How to do retrieval with contextual compression](/docs/how_to/contextual_compression/)\\n  - [How to convert Runnables as Tools](/docs/how_to/convert_runnable_to_tool/)\\n  - [How to create custom callback handlers](/docs/how_to/custom_callbacks/)\\n  - [How to create a custom chat model class](/docs/how_to/custom_chat_model/)\\n  - [How to create a custom LLM class](/docs/how_to/custom_llm/)\\n  - [Custom Retriever](/docs/how_to/custom_retriever/)\\n  - [How to create tools](/docs/how_to/custom_tools/)\\n  - [How to debug your LLM apps](/docs/how_to/debugging/)\\n  - [How to load CSVs](/docs/how_to/document_loader_csv/)\\n  - [How to load documents from a directory](/docs/how_to/document_loader_directory/)\\n  - [How to load HTML](/docs/how_to/document_loader_html/)\\n  - [How to load JSON](/docs/how_to/document_loader_json/)\\n  - [How to load Markdown](/docs/how_to/document_loader_markdown/)\\n  - [How to load Microsoft Office files](/docs/how_to/document_loader_office_file/)\\n  - [How to load PDFs](/docs/how_to/document_loader_pdf/)\\n  - [How to create a dynamic (self-constructing) chain](/docs/how_to/dynamic_chain/)\\n  - [Text embedding models](/docs/how_to/embed_text/)\\n  - [How to combine results from multiple retrievers](/docs/how_to/ensemble_retriever/)\\n  - [How to select examples from a LangSmith dataset](/docs/how_to/example_selectors_langsmith/)\\n  - [How to select examples by length](/docs/how_to/example_selectors_length_based/)\\n  - [How to select examples by maximal marginal relevance (MMR)](/docs/how_to/example_selectors_mmr/)\\n  - [How to select examples by n-gram overlap](/docs/how_to/example_selectors_ngram/)\\n  - [How to select examples by similarity](/docs/how_to/example_selectors_similarity/)\\n  - [How to use reference examples when doing extraction](/docs/how_to/extraction_examples/)\\n  - [How to handle long text when doing extraction](/docs/how_to/extraction_long_text/)\\n  - [How to use prompting alone (no tool calling) to do extraction](/docs/how_to/extraction_parse/)\\n  - [How to add fallbacks to a runnable](/docs/how_to/fallbacks/)\\n  - [How to filter messages](/docs/how_to/filter_messages/)\\n  - [Hybrid Search](/docs/how_to/hybrid/)\\n  - [How to use the LangChain indexing API](/docs/how_to/indexing/)\\n  - [How to inspect runnables](/docs/how_to/inspect/)\\n  - [LangChain Expression Language Cheatsheet](/docs/how_to/lcel_cheatsheet/)\\n  - [How to cache LLM responses](/docs/how_to/llm_caching/)\\n  - [How to track token usage for LLMs](/docs/how_to/llm_token_usage_tracking/)\\n  - [Run models locally](/docs/how_to/local_llms/)\\n  - [How to get log probabilities](/docs/how_to/logprobs/)\\n  - [How to reorder retrieved results to mitigate the \"lost in the middle\" effect](/docs/how_to/long_context_reorder/)\\n  - [How to split Markdown by Headers](/docs/how_to/markdown_header_metadata_splitter/)\\n  - [How to merge consecutive messages of the same type](/docs/how_to/merge_message_runs/)\\n  - [How to add message history](/docs/how_to/message_history/)\\n  - [How to migrate from legacy LangChain agents to LangGraph](/docs/how_to/migrate_agent/)\\n  - [How to retrieve using multiple vectors per document](/docs/how_to/multi_vector/)\\n  - [How to pass multimodal data directly to models](/docs/how_to/multimodal_inputs/)\\n  - [How to use multimodal prompts](/docs/how_to/multimodal_prompts/)\\n  - [How to create a custom Output Parser](/docs/how_to/output_parser_custom/)\\n  - [How to use the output-fixing parser](/docs/how_to/output_parser_fixing/)\\n  - [How to parse JSON output](/docs/how_to/output_parser_json/)\\n  - [How to retry when a parsing error occurs](/docs/how_to/output_parser_retry/)\\n  - [How to parse XML output](/docs/how_to/output_parser_xml/)\\n  - [How to parse YAML output](/docs/how_to/output_parser_yaml/)\\n  - [How to use the Parent Document Retriever](/docs/how_to/parent_document_retriever/)\\n  - [How to use LangChain with different Pydantic versions](/docs/how_to/pydantic_compatibility/)\\n  - [How to add chat history](/docs/how_to/qa_chat_history_how_to/)\\n  - [How to get a RAG application to add citations](/docs/how_to/qa_citations/)\\n  - [How to do per-user retrieval](/docs/how_to/qa_per_user/)\\n  - [How to get your RAG application to return sources](/docs/how_to/qa_sources/)\\n  - [How to stream results from your RAG application](/docs/how_to/qa_streaming/)\\n  - [How to split JSON data](/docs/how_to/recursive_json_splitter/)\\n  - [How to recursively split text by characters](/docs/how_to/recursive_text_splitter/)\\n  - [Response metadata](/docs/how_to/response_metadata/)\\n  - [How to pass runtime secrets to runnables](/docs/how_to/runnable_runtime_secrets/)\\n  - [How to do \"self-querying\" retrieval](/docs/how_to/self_query/)\\n  - [How to split text based on semantic similarity](/docs/how_to/semantic-chunker/)\\n  - [How to chain runnables](/docs/how_to/sequence/)\\n  - [How to save and load LangChain objects](/docs/how_to/serialization/)\\n  - [How to split text by tokens](/docs/how_to/split_by_token/)\\n  - [How to do question answering over CSVs](/docs/how_to/sql_csv/)\\n  - [How to deal with large databases when doing SQL question-answering](/docs/how_to/sql_large_db/)\\n  - [How to better prompt when doing SQL question-answering](/docs/how_to/sql_prompting/)\\n  - [How to do query validation as part of SQL question-answering](/docs/how_to/sql_query_checking/)\\n  - [How to stream runnables](/docs/how_to/streaming/)\\n  - [How to stream responses from an LLM](/docs/how_to/streaming_llm/)\\n  - [How to use a time-weighted vector store retriever](/docs/how_to/time_weighted_vectorstore/)\\n  - [How to return artifacts from a tool](/docs/how_to/tool_artifacts/)\\n  - [How to use chat models to call tools](/docs/how_to/tool_calling/)\\n  - [How to disable parallel tool calling](/docs/how_to/tool_calling_parallel/)\\n  - [How to force models to call a tool](/docs/how_to/tool_choice/)\\n  - [How to access the RunnableConfig from a tool](/docs/how_to/tool_configure/)\\n  - [How to pass tool outputs to chat models](/docs/how_to/tool_results_pass_to_model/)\\n  - [How to pass run time values to tools](/docs/how_to/tool_runtime/)\\n  - [How to stream events from a tool](/docs/how_to/tool_stream_events/)\\n  - [How to stream tool calls](/docs/how_to/tool_streaming/)\\n  - [How to convert tools to OpenAI Functions](/docs/how_to/tools_as_openai_functions/)\\n  - [How to handle tool errors](/docs/how_to/tools_error/)\\n  - [How to use few-shot prompting with tool calling](/docs/how_to/tools_few_shot/)\\n  - [How to add a human-in-the-loop for tools](/docs/how_to/tools_human/)\\n  - [How to bind model-specific tools](/docs/how_to/tools_model_specific/)\\n  - [How to trim messages](/docs/how_to/trim_messages/)\\n  - [How to create and query vector stores](/docs/how_to/vectorstores/)\\n- [Conceptual guide](/docs/concepts/)\\n- Ecosystem\\n\\n  - [ü¶úüõ†Ô∏è LangSmith](https://docs.smith.langchain.com/)\\n  - [ü¶úüï∏Ô∏è LangGraph](https://langchain-ai.github.io/langgraph/)\\n- Versions\\n\\n  - [v0.3](/docs/versions/v0_3/)\\n  - v0.2\\n\\n  - [Pydantic compatibility](/docs/how_to/pydantic_compatibility/)\\n  - [Migrating from v0.0 chains](/docs/versions/migrating_chains/)\\n\\n    - [How to migrate from v0.0 chains](/docs/versions/migrating_chains/)\\n    - [Migrating from ConstitutionalChain](/docs/versions/migrating_chains/constitutional_chain/)\\n    - [Migrating from ConversationalChain](/docs/versions/migrating_chains/conversation_chain/)\\n    - [Migrating from ConversationalRetrievalChain](/docs/versions/migrating_chains/conversation_retrieval_chain/)\\n    - [Migrating from LLMChain](/docs/versions/migrating_chains/llm_chain/)\\n    - [Migrating from LLMMathChain](/docs/versions/migrating_chains/llm_math_chain/)\\n    - [Migrating from LLMRouterChain](/docs/versions/migrating_chains/llm_router_chain/)\\n    - [Migrating from MapReduceDocumentsChain](/docs/versions/migrating_chains/map_reduce_chain/)\\n    - [Migrating from MapRerankDocumentsChain](/docs/versions/migrating_chains/map_rerank_docs_chain/)\\n    - [Migrating from MultiPromptChain](/docs/versions/migrating_chains/multi_prompt_chain/)\\n    - [Migrating from RefineDocumentsChain](/docs/versions/migrating_chains/refine_docs_chain/)\\n    - [Migrating from RetrievalQA](/docs/versions/migrating_chains/retrieval_qa/)\\n    - [Migrating from StuffDocumentsChain](/docs/versions/migrating_chains/stuff_docs_chain/)\\n  - [Migrating from v0.0 memory](/docs/versions/migrating_memory/)\\n\\n    - [How to migrate from v0.0 memory](/docs/versions/migrating_memory/)\\n    - [Migrating off ConversationBufferMemory or ConversationStringBufferMemory](/docs/versions/migrating_memory/conversation_buffer_memory/)\\n    - [Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory](/docs/versions/migrating_memory/conversation_buffer_window_memory/)\\n    - [Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory](/docs/versions/migrating_memory/conversation_summary_memory/)\\n  - [Release policy](/docs/versions/release_policy/)\\n- [Security](/docs/security/)\\n\\n- [Home page](/)\\n- Introduction\\n\\nOn this page\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\n- **Development**: Build your applications using LangChain\\'s open-source [building blocks](/docs/concepts/#langchain-expression-language-lcel), [components](/docs/concepts/), and [third-party integrations](/docs/integrations/platforms/).\\nUse [LangGraph](/docs/concepts/#langgraph) to build stateful agents with first-class streaming and human-in-the-loop support.\\n- **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your chains, so that you can continuously optimize and deploy with confidence.\\n- **Deployment**: Turn your LangGraph applications into production-ready APIs and Assistants with [LangGraph Cloud](https://langchain-ai.github.io/langgraph/cloud/).\\n\\n![Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.](https://python.langchain.com/svg/langchain_stack_062024.svg)\\n\\nConcretely, the framework consists of the following open-source libraries:\\n\\n- **`langchain-core`**: Base abstractions and LangChain Expression Language.\\n- **`langchain-community`**: Third party integrations.\\n  - Partner packages (e.g. **`langchain-openai`**, **`langchain-anthropic`**, etc.): Some integrations have been further split into their own lightweight packages that only depend on **`langchain-core`**.\\n- **`langchain`**: Chains, agents, and retrieval strategies that make up an application\\'s cognitive architecture.\\n- **[LangGraph](https://langchain-ai.github.io/langgraph)**: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. Integrates smoothly with LangChain, but can be used without it.\\n- **[LangServe](/docs/langserve/)**: Deploy LangChain chains as REST APIs.\\n- **[LangSmith](https://docs.smith.langchain.com)**: A developer platform that lets you debug, test, evaluate, and monitor LLM applications.\\n\\nnote\\n\\nThese docs focus on the Python LangChain library. [Head here](https://js.langchain.com) for docs on the JavaScript LangChain library.\\n\\n## [Tutorials](/docs/tutorials/) [\\u200b](\\\\#tutorials \"Direct link to tutorials\")\\n\\nIf you\\'re looking to build something specific or are more of a hands-on learner, check out our [tutorials section](/docs/tutorials/).\\nThis is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\n- [Build a Simple LLM Application](/docs/tutorials/llm_chain/)\\n- [Build a Chatbot](/docs/tutorials/chatbot/)\\n- [Build an Agent](/docs/tutorials/agents/)\\n- [Introduction to LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\\n\\nExplore the full list of LangChain tutorials [here](/docs/tutorials/), and check out other [LangGraph tutorials here](https://langchain-ai.github.io/langgraph/tutorials/). To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_, available [here](https://academy.langchain.com/courses/intro-to-langgraph).\\n\\n## [How-to guides](/docs/how_to/) [\\u200b](\\\\#how-to-guides \"Direct link to how-to-guides\")\\n\\n[Here](/docs/how_to/) you‚Äôll find short answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions.\\nThese how-to guides don‚Äôt cover topics in depth ‚Äì you‚Äôll find that material in the [Tutorials](/docs/tutorials/) and the [API Reference](https://python.langchain.com/api_reference/).\\nHowever, these guides will help you quickly accomplish common tasks.\\n\\nCheck out [LangGraph-specific how-tos here](https://langchain-ai.github.io/langgraph/how-tos/).\\n\\n## [Conceptual guide](/docs/concepts/) [\\u200b](\\\\#conceptual-guide \"Direct link to conceptual-guide\")\\n\\nIntroductions to all the key parts of LangChain you‚Äôll need to know! [Here](/docs/concepts/) you\\'ll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [this page](https://langchain-ai.github.io/langgraph/concepts/).\\n\\n## [API reference](https://python.langchain.com/api_reference/) [\\u200b](\\\\#api-reference \"Direct link to api-reference\")\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem [\\u200b](\\\\#ecosystem \"Direct link to Ecosystem\")\\n\\n### [ü¶úüõ†Ô∏è LangSmith](https://docs.smith.langchain.com) [\\u200b](\\\\#Ô∏è-langsmith \"Direct link to Ô∏è-langsmith\")\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ü¶úüï∏Ô∏è LangGraph](https://langchain-ai.github.io/langgraph) [\\u200b](\\\\#Ô∏è-langgraph \"Direct link to Ô∏è-langgraph\")\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it.\\n\\n## Additional resources [\\u200b](\\\\#additional-resources \"Direct link to Additional resources\")\\n\\n### [Versions](/docs/versions/v0_3/) [\\u200b](\\\\#versions \"Direct link to versions\")\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [Security](/docs/security/) [\\u200b](\\\\#security \"Direct link to security\")\\n\\nRead up on [security](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [Integrations](/docs/integrations/providers/) [\\u200b](\\\\#integrations \"Direct link to integrations\")\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of [integrations](/docs/integrations/providers/).\\n\\n### [Contributing](/docs/contributing/) [\\u200b](\\\\#contributing \"Direct link to contributing\")\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n[Edit this page](https://github.com/langchain-ai/langchain/edit/master/docs/docs/introduction.mdx)\\n\\n* * *\\n\\n#### Was this page helpful?\\n\\n#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchain/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CIssue+related+to+/docs/introduction/%3E&url=https://python.langchain.com/docs/introduction/).\\n\\n[Next\\\\\\\\\\n\\\\\\\\\\nTutorials](/docs/tutorials/)\\n\\n- [Tutorials](#tutorials)\\n- [How-to guides](#how-to-guides)\\n- [Conceptual guide](#conceptual-guide)\\n- [API reference](#api-reference)\\n- [Ecosystem](#ecosystem)\\n  - [ü¶úüõ†Ô∏è LangSmith](#Ô∏è-langsmith)\\n  - [ü¶úüï∏Ô∏è LangGraph](#Ô∏è-langgraph)\\n- [Additional resources](#additional-resources)\\n  - [Versions](#versions)\\n  - [Security](#security)\\n  - [Integrations](#integrations)\\n  - [Contributing](#contributing)\\n\\nCommunity\\n\\n- [Twitter](https://twitter.com/LangChainAI)\\n\\nGitHub\\n\\n- [Organization](https://github.com/langchain-ai)\\n- [Python](https://github.com/langchain-ai/langchain)\\n- [JS/TS](https://github.com/langchain-ai/langchainjs)\\n\\nMore\\n\\n- [Homepage](https://langchain.com)\\n- [Blog](https://blog.langchain.dev)\\n- [YouTube](https://www.youtube.com/@LangChain)\\n\\nCopyright ¬© 2024 LangChain, Inc.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "api_key = \"fc-6bc21951e5eb4c8db24ccc90728855e6\"\n",
    "loader = FireCrawlLoader(url=\"https://python.langchain.com/docs/introduction/\", mode = \"crawl\", api_key=api_key)\n",
    "\n",
    "docs = loader.load()\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'ogUrl': 'https://python.langchain.com/docs/integrations/document_loaders/firecrawl/', 'title': 'FireCrawl | ü¶úÔ∏èüîó LangChain', 'ogImage': 'https://python.langchain.com/img/brand/theme-image.png', 'ogTitle': 'FireCrawl | ü¶úÔ∏èüîó LangChain', 'language': 'en', 'sourceURL': 'https://python.langchain.com/docs/integrations/document_loaders/firecrawl/', 'description': 'FireCrawl crawls and convert any website into LLM-ready data. It crawls all accessible subpages and give you clean markdown and metadata for each. No sitemap required.', 'ogDescription': 'FireCrawl crawls and convert any website into LLM-ready data. It crawls all accessible subpages and give you clean markdown and metadata for each. No sitemap required.', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content='[Skip to main content](#__docusaurus_skipToContent_fallback)\\n\\n[![ü¶úÔ∏èüîó LangChain](https://python.langchain.com/img/brand/wordmark.png)](/)[Integrations](/docs/integrations/platforms/) [API Reference](https://python.langchain.com/api_reference/)\\n\\nMore\\n\\n- [Contributing](/docs/contributing/)\\n- [People](/docs/people/)\\n- * * *\\n\\n- [LangSmith](https://docs.smith.langchain.com)\\n- [LangGraph](https://langchain-ai.github.io/langgraph/)\\n- [LangChain Hub](https://smith.langchain.com/hub)\\n- [LangChain JS/TS](https://js.langchain.com)\\n\\nv0.3\\n\\n- [v0.3](/docs/introduction/)\\n- [v0.2](https://python.langchain.com/v0.2/docs/introduction)\\n- [v0.1](https://python.langchain.com/v0.1/docs/get_started/introduction)\\n\\n[üí¨](https://chat.langchain.com)  [GitHub repository](https://github.com/langchain-ai/langchain)\\n\\nSearch`` `K`\\n\\n- [Providers](/docs/integrations/platforms/)\\n\\n  - [Providers](/docs/integrations/platforms/)\\n  - [Anthropic](/docs/integrations/platforms/anthropic/)\\n  - [AWS](/docs/integrations/platforms/aws/)\\n  - [Google](/docs/integrations/platforms/google/)\\n  - [Hugging Face](/docs/integrations/platforms/huggingface/)\\n  - [Microsoft](/docs/integrations/platforms/microsoft/)\\n  - [OpenAI](/docs/integrations/platforms/openai/)\\n  - [More](/docs/integrations/providers/)\\n- [Components](/docs/integrations/components/)\\n\\n  - [Chat models](/docs/integrations/chat/)\\n\\n    - [Chat models](/docs/integrations/chat/)\\n    - [AI21 Labs](/docs/integrations/chat/ai21/)\\n    - [Alibaba Cloud PAI EAS](/docs/integrations/chat/alibaba_cloud_pai_eas/)\\n    - [Anthropic](/docs/integrations/chat/anthropic/)\\n    - [\\\\[Deprecated\\\\] Experimental Anthropic Tools Wrapper](/docs/integrations/chat/anthropic_functions/)\\n    - [Anyscale](/docs/integrations/chat/anyscale/)\\n    - [Azure OpenAI](/docs/integrations/chat/azure_chat_openai/)\\n    - [Azure ML Endpoint](/docs/integrations/chat/azureml_chat_endpoint/)\\n    - [Baichuan Chat](/docs/integrations/chat/baichuan/)\\n    - [Baidu Qianfan](/docs/integrations/chat/baidu_qianfan_endpoint/)\\n    - [AWS Bedrock](/docs/integrations/chat/bedrock/)\\n    - [Cerebras](/docs/integrations/chat/cerebras/)\\n    - [Cohere](/docs/integrations/chat/cohere/)\\n    - [Coze Chat](/docs/integrations/chat/coze/)\\n    - [Dappier AI](/docs/integrations/chat/dappier/)\\n    - [Databricks](/docs/integrations/chat/databricks/)\\n    - [DeepInfra](/docs/integrations/chat/deepinfra/)\\n    - [Eden AI](/docs/integrations/chat/edenai/)\\n    - [Ernie Bot Chat](/docs/integrations/chat/ernie/)\\n    - [EverlyAI](/docs/integrations/chat/everlyai/)\\n    - [Fireworks](/docs/integrations/chat/fireworks/)\\n    - [Friendli](/docs/integrations/chat/friendli/)\\n    - [GigaChat](/docs/integrations/chat/gigachat/)\\n    - [Google AI](/docs/integrations/chat/google_generative_ai/)\\n    - [Google Cloud Vertex AI](/docs/integrations/chat/google_vertex_ai_palm/)\\n    - [GPTRouter](/docs/integrations/chat/gpt_router/)\\n    - [Groq](/docs/integrations/chat/groq/)\\n    - [ChatHuggingFace](/docs/integrations/chat/huggingface/)\\n    - [IBM watsonx.ai](/docs/integrations/chat/ibm_watsonx/)\\n    - [JinaChat](/docs/integrations/chat/jinachat/)\\n    - [Kinetica](/docs/integrations/chat/kinetica/)\\n    - [Konko](/docs/integrations/chat/konko/)\\n    - [LiteLLM](/docs/integrations/chat/litellm/)\\n    - [LiteLLM Router](/docs/integrations/chat/litellm_router/)\\n    - [Llama 2 Chat](/docs/integrations/chat/llama2_chat/)\\n    - [Llama API](/docs/integrations/chat/llama_api/)\\n    - [LlamaEdge](/docs/integrations/chat/llama_edge/)\\n    - [Llama.cpp](/docs/integrations/chat/llamacpp/)\\n    - [maritalk](/docs/integrations/chat/maritalk/)\\n    - [MiniMax](/docs/integrations/chat/minimax/)\\n    - [MistralAI](/docs/integrations/chat/mistralai/)\\n    - [MLX](/docs/integrations/chat/mlx/)\\n    - [Moonshot](/docs/integrations/chat/moonshot/)\\n    - [NVIDIA AI Endpoints](/docs/integrations/chat/nvidia_ai_endpoints/)\\n    - [OCIGenAI](/docs/integrations/chat/oci_generative_ai/)\\n    - [ChatOctoAI](/docs/integrations/chat/octoai/)\\n    - [Ollama](/docs/integrations/chat/ollama/)\\n    - [OpenAI](/docs/integrations/chat/openai/)\\n    - [Perplexity](/docs/integrations/chat/perplexity/)\\n    - [PremAI](/docs/integrations/chat/premai/)\\n    - [PromptLayer ChatOpenAI](/docs/integrations/chat/promptlayer_chatopenai/)\\n    - [Snowflake Cortex](/docs/integrations/chat/snowflake/)\\n    - [solar](/docs/integrations/chat/solar/)\\n    - [SparkLLM Chat](/docs/integrations/chat/sparkllm/)\\n    - [Nebula (Symbl.ai)](/docs/integrations/chat/symblai_nebula/)\\n    - [Tencent Hunyuan](/docs/integrations/chat/tencent_hunyuan/)\\n    - [Together](/docs/integrations/chat/together/)\\n    - [Tongyi Qwen](/docs/integrations/chat/tongyi/)\\n    - [Upstage](/docs/integrations/chat/upstage/)\\n    - [vLLM Chat](/docs/integrations/chat/vllm/)\\n    - [Volc Enging Maas](/docs/integrations/chat/volcengine_maas/)\\n    - [YandexGPT](/docs/integrations/chat/yandex/)\\n    - [ChatYI](/docs/integrations/chat/yi/)\\n    - [Yuan2.0](/docs/integrations/chat/yuan2/)\\n    - [ZHIPU AI](/docs/integrations/chat/zhipuai/)\\n  - [LLMs](/docs/integrations/llms/)\\n\\n    - [LLMs](/docs/integrations/llms/)\\n    - [AI21 Labs](/docs/integrations/llms/ai21/)\\n    - [Aleph Alpha](/docs/integrations/llms/aleph_alpha/)\\n    - [Alibaba Cloud PAI EAS](/docs/integrations/llms/alibabacloud_pai_eas_endpoint/)\\n    - [Amazon API Gateway](/docs/integrations/llms/amazon_api_gateway/)\\n    - [Anthropic](/docs/integrations/llms/anthropic/)\\n    - [Anyscale](/docs/integrations/llms/anyscale/)\\n    - [Aphrodite Engine](/docs/integrations/llms/aphrodite/)\\n    - [Arcee](/docs/integrations/llms/arcee/)\\n    - [Azure ML](/docs/integrations/llms/azure_ml/)\\n    - [Azure OpenAI](/docs/integrations/llms/azure_openai/)\\n    - [Baichuan LLM](/docs/integrations/llms/baichuan/)\\n    - [Baidu Qianfan](/docs/integrations/llms/baidu_qianfan_endpoint/)\\n    - [Banana](/docs/integrations/llms/banana/)\\n    - [Baseten](/docs/integrations/llms/baseten/)\\n    - [Beam](/docs/integrations/llms/beam/)\\n    - [Bedrock](/docs/integrations/llms/bedrock/)\\n    - [Bittensor](/docs/integrations/llms/bittensor/)\\n    - [CerebriumAI](/docs/integrations/llms/cerebriumai/)\\n    - [ChatGLM](/docs/integrations/llms/chatglm/)\\n    - [Clarifai](/docs/integrations/llms/clarifai/)\\n    - [Cloudflare Workers AI](/docs/integrations/llms/cloudflare_workersai/)\\n    - [Cohere](/docs/integrations/llms/cohere/)\\n    - [C Transformers](/docs/integrations/llms/ctransformers/)\\n    - [CTranslate2](/docs/integrations/llms/ctranslate2/)\\n    - [Databricks](/docs/integrations/llms/databricks/)\\n    - [DeepInfra](/docs/integrations/llms/deepinfra/)\\n    - [DeepSparse](/docs/integrations/llms/deepsparse/)\\n    - [Eden AI](/docs/integrations/llms/edenai/)\\n    - [ExLlamaV2](/docs/integrations/llms/exllamav2/)\\n    - [Fireworks](/docs/integrations/llms/fireworks/)\\n    - [ForefrontAI](/docs/integrations/llms/forefrontai/)\\n    - [Friendli](/docs/integrations/llms/friendli/)\\n    - [GigaChat](/docs/integrations/llms/gigachat/)\\n    - [Google AI](/docs/integrations/llms/google_ai/)\\n    - [Google Cloud Vertex AI](/docs/integrations/llms/google_vertex_ai_palm/)\\n    - [GooseAI](/docs/integrations/llms/gooseai/)\\n    - [GPT4All](/docs/integrations/llms/gpt4all/)\\n    - [Gradient](/docs/integrations/llms/gradient/)\\n    - [Huggingface Endpoints](/docs/integrations/llms/huggingface_endpoint/)\\n    - [Hugging Face Local Pipelines](/docs/integrations/llms/huggingface_pipelines/)\\n    - [IBM watsonx.ai](/docs/integrations/llms/ibm_watsonx/)\\n    - [IPEX-LLM](/docs/integrations/llms/ipex_llm/)\\n    - [Javelin AI Gateway Tutorial](/docs/integrations/llms/javelin/)\\n    - [JSONFormer](/docs/integrations/llms/jsonformer_experimental/)\\n    - [KoboldAI API](/docs/integrations/llms/koboldai/)\\n    - [Konko](/docs/integrations/llms/konko/)\\n    - [Layerup Security](/docs/integrations/llms/layerup_security/)\\n    - [Llama.cpp](/docs/integrations/llms/llamacpp/)\\n    - [Llamafile](/docs/integrations/llms/llamafile/)\\n    - [LM Format Enforcer](/docs/integrations/llms/lmformatenforcer_experimental/)\\n    - [Manifest](/docs/integrations/llms/manifest/)\\n    - [Minimax](/docs/integrations/llms/minimax/)\\n    - [MLX Local Pipelines](/docs/integrations/llms/mlx_pipelines/)\\n    - [Modal](/docs/integrations/llms/modal/)\\n    - [MoonshotChat](/docs/integrations/llms/moonshot/)\\n    - [MosaicML](/docs/integrations/llms/mosaicml/)\\n    - [NLP Cloud](/docs/integrations/llms/nlpcloud/)\\n    - [oci\\\\_generative\\\\_ai](/docs/integrations/llms/oci_generative_ai/)\\n    - [OCI Data Science Model Deployment Endpoint](/docs/integrations/llms/oci_model_deployment_endpoint/)\\n    - [OctoAI](/docs/integrations/llms/octoai/)\\n    - [Ollama](/docs/integrations/llms/ollama/)\\n    - [OpaquePrompts](/docs/integrations/llms/opaqueprompts/)\\n    - [OpenAI](/docs/integrations/llms/openai/)\\n    - [OpenLLM](/docs/integrations/llms/openllm/)\\n    - [OpenLM](/docs/integrations/llms/openlm/)\\n    - [OpenVINO](/docs/integrations/llms/openvino/)\\n    - [Petals](/docs/integrations/llms/petals/)\\n    - [PipelineAI](/docs/integrations/llms/pipelineai/)\\n    - [Predibase](/docs/integrations/llms/predibase/)\\n    - [Prediction Guard](/docs/integrations/llms/predictionguard/)\\n    - [PromptLayer OpenAI](/docs/integrations/llms/promptlayer_openai/)\\n    - [RELLM](/docs/integrations/llms/rellm_experimental/)\\n    - [Replicate](/docs/integrations/llms/replicate/)\\n    - [Runhouse](/docs/integrations/llms/runhouse/)\\n    - [SageMakerEndpoint](/docs/integrations/llms/sagemaker/)\\n    - [SambaNova](/docs/integrations/llms/sambanova/)\\n    - [Solar](/docs/integrations/llms/solar/)\\n    - [SparkLLM](/docs/integrations/llms/sparkllm/)\\n    - [StochasticAI](/docs/integrations/llms/stochasticai/)\\n    - [Nebula (Symbl.ai)](/docs/integrations/llms/symblai_nebula/)\\n    - [TextGen](/docs/integrations/llms/textgen/)\\n    - [Titan Takeoff](/docs/integrations/llms/titan_takeoff/)\\n    - [Together AI](/docs/integrations/llms/together/)\\n    - [Tongyi Qwen](/docs/integrations/llms/tongyi/)\\n    - [vLLM](/docs/integrations/llms/vllm/)\\n    - [Volc Engine Maas](/docs/integrations/llms/volcengine_maas/)\\n    - [Intel Weight-Only Quantization](/docs/integrations/llms/weight_only_quantization/)\\n    - [Writer](/docs/integrations/llms/writer/)\\n    - [Xorbits Inference (Xinference)](/docs/integrations/llms/xinference/)\\n    - [YandexGPT](/docs/integrations/llms/yandex/)\\n    - [Yi](/docs/integrations/llms/yi/)\\n    - [Yuan2.0](/docs/integrations/llms/yuan2/)\\n  - [Embedding models](/docs/integrations/text_embedding/)\\n\\n    - [Embedding models](/docs/integrations/text_embedding/)\\n    - [AI21](/docs/integrations/text_embedding/ai21/)\\n    - [Aleph Alpha](/docs/integrations/text_embedding/aleph_alpha/)\\n    - [Anyscale](/docs/integrations/text_embedding/anyscale/)\\n    - [ascend](/docs/integrations/text_embedding/ascend/)\\n    - [AwaDB](/docs/integrations/text_embedding/awadb/)\\n    - [AzureOpenAI](/docs/integrations/text_embedding/azureopenai/)\\n    - [Baichuan Text Embeddings](/docs/integrations/text_embedding/baichuan/)\\n    - [Baidu Qianfan](/docs/integrations/text_embedding/baidu_qianfan_endpoint/)\\n    - [Bedrock](/docs/integrations/text_embedding/bedrock/)\\n    - [BGE on Hugging Face](/docs/integrations/text_embedding/bge_huggingface/)\\n    - [Bookend AI](/docs/integrations/text_embedding/bookend/)\\n    - [Clarifai](/docs/integrations/text_embedding/clarifai/)\\n    - [Cloudflare Workers AI](/docs/integrations/text_embedding/cloudflare_workersai/)\\n    - [Clova Embeddings](/docs/integrations/text_embedding/clova/)\\n    - [Cohere](/docs/integrations/text_embedding/cohere/)\\n    - [DashScope](/docs/integrations/text_embedding/dashscope/)\\n    - [Databricks](/docs/integrations/text_embedding/databricks/)\\n    - [DeepInfra](/docs/integrations/text_embedding/deepinfra/)\\n    - [EDEN AI](/docs/integrations/text_embedding/edenai/)\\n    - [Elasticsearch](/docs/integrations/text_embedding/elasticsearch/)\\n    - [Embaas](/docs/integrations/text_embedding/embaas/)\\n    - [ERNIE](/docs/integrations/text_embedding/ernie/)\\n    - [Fake Embeddings](/docs/integrations/text_embedding/fake/)\\n    - [FastEmbed by Qdrant](/docs/integrations/text_embedding/fastembed/)\\n    - [Fireworks](/docs/integrations/text_embedding/fireworks/)\\n    - [GigaChat](/docs/integrations/text_embedding/gigachat/)\\n    - [Google Generative AI Embeddings](/docs/integrations/text_embedding/google_generative_ai/)\\n    - [Google Vertex AI](/docs/integrations/text_embedding/google_vertex_ai_palm/)\\n    - [GPT4All](/docs/integrations/text_embedding/gpt4all/)\\n    - [Gradient](/docs/integrations/text_embedding/gradient/)\\n    - [Hugging Face](/docs/integrations/text_embedding/huggingfacehub/)\\n    - [IBM watsonx.ai](/docs/integrations/text_embedding/ibm_watsonx/)\\n    - [Infinity](/docs/integrations/text_embedding/infinity/)\\n    - [Instruct Embeddings on Hugging Face](/docs/integrations/text_embedding/instruct_embeddings/)\\n    - [Local BGE Embeddings with IPEX-LLM on Intel CPU](/docs/integrations/text_embedding/ipex_llm/)\\n    - [Local BGE Embeddings with IPEX-LLM on Intel GPU](/docs/integrations/text_embedding/ipex_llm_gpu/)\\n    - [Intel¬Æ Extension for Transformers Quantized Text Embeddings](/docs/integrations/text_embedding/itrex/)\\n    - [Jina](/docs/integrations/text_embedding/jina/)\\n    - [John Snow Labs](/docs/integrations/text_embedding/johnsnowlabs_embedding/)\\n    - [LASER Language-Agnostic SEntence Representations Embeddings by Meta AI](/docs/integrations/text_embedding/laser/)\\n    - [Llama.cpp](/docs/integrations/text_embedding/llamacpp/)\\n    - [llamafile](/docs/integrations/text_embedding/llamafile/)\\n    - [LLMRails](/docs/integrations/text_embedding/llm_rails/)\\n    - [LocalAI](/docs/integrations/text_embedding/localai/)\\n    - [MiniMax](/docs/integrations/text_embedding/minimax/)\\n    - [MistralAI](/docs/integrations/text_embedding/mistralai/)\\n    - [ModelScope](/docs/integrations/text_embedding/modelscope_hub/)\\n    - [MosaicML](/docs/integrations/text_embedding/mosaicml/)\\n    - [NLP Cloud](/docs/integrations/text_embedding/nlp_cloud/)\\n    - [Nomic](/docs/integrations/text_embedding/nomic/)\\n    - [NVIDIA NIMs](/docs/integrations/text_embedding/nvidia_ai_endpoints/)\\n    - [Oracle Cloud Infrastructure Generative AI](/docs/integrations/text_embedding/oci_generative_ai/)\\n    - [Ollama](/docs/integrations/text_embedding/ollama/)\\n    - [OpenClip](/docs/integrations/text_embedding/open_clip/)\\n    - [OpenAI](/docs/integrations/text_embedding/openai/)\\n    - [OpenVINO](/docs/integrations/text_embedding/openvino/)\\n    - [Embedding Documents using Optimized and Quantized Embedders](/docs/integrations/text_embedding/optimum_intel/)\\n    - [Oracle AI Vector Search: Generate Embeddings](/docs/integrations/text_embedding/oracleai/)\\n    - [OVHcloud](/docs/integrations/text_embedding/ovhcloud/)\\n    - [Pinecone Embeddings](/docs/integrations/text_embedding/pinecone/)\\n    - [PremAI](/docs/integrations/text_embedding/premai/)\\n    - [SageMaker](/docs/integrations/text_embedding/sagemaker-endpoint/)\\n    - [SambaNova](/docs/integrations/text_embedding/sambanova/)\\n    - [Self Hosted](/docs/integrations/text_embedding/self-hosted/)\\n    - [Sentence Transformers on Hugging Face](/docs/integrations/text_embedding/sentence_transformers/)\\n    - [Solar](/docs/integrations/text_embedding/solar/)\\n    - [SpaCy](/docs/integrations/text_embedding/spacy_embedding/)\\n    - [SparkLLM Text Embeddings](/docs/integrations/text_embedding/sparkllm/)\\n    - [TensorFlow Hub](/docs/integrations/text_embedding/tensorflowhub/)\\n    - [Text Embeddings Inference](/docs/integrations/text_embedding/text_embeddings_inference/)\\n    - [TextEmbed - Embedding Inference Server](/docs/integrations/text_embedding/textembed/)\\n    - [Titan Takeoff](/docs/integrations/text_embedding/titan_takeoff/)\\n    - [Together AI](/docs/integrations/text_embedding/together/)\\n    - [Upstage](/docs/integrations/text_embedding/upstage/)\\n    - [Volc Engine](/docs/integrations/text_embedding/volcengine/)\\n    - [Voyage AI](/docs/integrations/text_embedding/voyageai/)\\n    - [Xorbits inference (Xinference)](/docs/integrations/text_embedding/xinference/)\\n    - [YandexGPT](/docs/integrations/text_embedding/yandex/)\\n    - [ZhipuAI](/docs/integrations/text_embedding/zhipuai/)\\n  - [Document loaders](/docs/integrations/document_loaders/)\\n\\n    - [Document loaders](/docs/integrations/document_loaders/)\\n    - [acreom](/docs/integrations/document_loaders/acreom/)\\n    - [AirbyteLoader](/docs/integrations/document_loaders/airbyte/)\\n    - [Airbyte CDK (Deprecated)](/docs/integrations/document_loaders/airbyte_cdk/)\\n    - [Airbyte Gong (Deprecated)](/docs/integrations/document_loaders/airbyte_gong/)\\n    - [Airbyte Hubspot (Deprecated)](/docs/integrations/document_loaders/airbyte_hubspot/)\\n    - [Airbyte JSON (Deprecated)](/docs/integrations/document_loaders/airbyte_json/)\\n    - [Airbyte Salesforce (Deprecated)](/docs/integrations/document_loaders/airbyte_salesforce/)\\n    - [Airbyte Shopify (Deprecated)](/docs/integrations/document_loaders/airbyte_shopify/)\\n    - [Airbyte Stripe (Deprecated)](/docs/integrations/document_loaders/airbyte_stripe/)\\n    - [Airbyte Typeform (Deprecated)](/docs/integrations/document_loaders/airbyte_typeform/)\\n    - [Airbyte Zendesk Support (Deprecated)](/docs/integrations/document_loaders/airbyte_zendesk_support/)\\n    - [Airtable](/docs/integrations/document_loaders/airtable/)\\n    - [Alibaba Cloud MaxCompute](/docs/integrations/document_loaders/alibaba_cloud_maxcompute/)\\n    - [Amazon Textract](/docs/integrations/document_loaders/amazon_textract/)\\n    - [Apify Dataset](/docs/integrations/document_loaders/apify_dataset/)\\n    - [ArcGIS](/docs/integrations/document_loaders/arcgis/)\\n    - [ArxivLoader](/docs/integrations/document_loaders/arxiv/)\\n    - [AssemblyAI Audio Transcripts](/docs/integrations/document_loaders/assemblyai/)\\n    - [AstraDB](/docs/integrations/document_loaders/astradb/)\\n    - [Async Chromium](/docs/integrations/document_loaders/async_chromium/)\\n    - [AsyncHtml](/docs/integrations/document_loaders/async_html/)\\n    - [Athena](/docs/integrations/document_loaders/athena/)\\n    - [AWS S3 Directory](/docs/integrations/document_loaders/aws_s3_directory/)\\n    - [AWS S3 File](/docs/integrations/document_loaders/aws_s3_file/)\\n    - [AZLyrics](/docs/integrations/document_loaders/azlyrics/)\\n    - [Azure AI Data](/docs/integrations/document_loaders/azure_ai_data/)\\n    - [Azure Blob Storage Container](/docs/integrations/document_loaders/azure_blob_storage_container/)\\n    - [Azure Blob Storage File](/docs/integrations/document_loaders/azure_blob_storage_file/)\\n    - [Azure AI Document Intelligence](/docs/integrations/document_loaders/azure_document_intelligence/)\\n    - [BibTeX](/docs/integrations/document_loaders/bibtex/)\\n    - [BiliBili](/docs/integrations/document_loaders/bilibili/)\\n    - [Blackboard](/docs/integrations/document_loaders/blackboard/)\\n    - [Blockchain](/docs/integrations/document_loaders/blockchain/)\\n    - [Box](/docs/integrations/document_loaders/box/)\\n    - [Brave Search](/docs/integrations/document_loaders/brave_search/)\\n    - [Browserbase](/docs/integrations/document_loaders/browserbase/)\\n    - [Browserless](/docs/integrations/document_loaders/browserless/)\\n    - [BSHTMLLoader](/docs/integrations/document_loaders/bshtml/)\\n    - [Cassandra](/docs/integrations/document_loaders/cassandra/)\\n    - [ChatGPT Data](/docs/integrations/document_loaders/chatgpt_loader/)\\n    - [College Confidential](/docs/integrations/document_loaders/college_confidential/)\\n    - [Concurrent Loader](/docs/integrations/document_loaders/concurrent/)\\n    - [Confluence](/docs/integrations/document_loaders/confluence/)\\n    - [CoNLL-U](/docs/integrations/document_loaders/conll-u/)\\n    - [Copy Paste](/docs/integrations/document_loaders/copypaste/)\\n    - [Couchbase](/docs/integrations/document_loaders/couchbase/)\\n    - [CSV](/docs/integrations/document_loaders/csv/)\\n    - [Cube Semantic Layer](/docs/integrations/document_loaders/cube_semantic/)\\n    - [Datadog Logs](/docs/integrations/document_loaders/datadog_logs/)\\n    - [Dedoc](/docs/integrations/document_loaders/dedoc/)\\n    - [Diffbot](/docs/integrations/document_loaders/diffbot/)\\n    - [Discord](/docs/integrations/document_loaders/discord/)\\n    - [Docugami](/docs/integrations/document_loaders/docugami/)\\n    - [Docusaurus](/docs/integrations/document_loaders/docusaurus/)\\n    - [Dropbox](/docs/integrations/document_loaders/dropbox/)\\n    - [DuckDB](/docs/integrations/document_loaders/duckdb/)\\n    - [Email](/docs/integrations/document_loaders/email/)\\n    - [EPub](/docs/integrations/document_loaders/epub/)\\n    - [Etherscan](/docs/integrations/document_loaders/etherscan/)\\n    - [EverNote](/docs/integrations/document_loaders/evernote/)\\n    - example\\\\_data\\n\\n    - [Facebook Chat](/docs/integrations/document_loaders/facebook_chat/)\\n    - [Fauna](/docs/integrations/document_loaders/fauna/)\\n    - [Figma](/docs/integrations/document_loaders/figma/)\\n    - [FireCrawl](/docs/integrations/document_loaders/firecrawl/)\\n    - [Geopandas](/docs/integrations/document_loaders/geopandas/)\\n    - [Git](/docs/integrations/document_loaders/git/)\\n    - [GitBook](/docs/integrations/document_loaders/gitbook/)\\n    - [GitHub](/docs/integrations/document_loaders/github/)\\n    - [Glue Catalog](/docs/integrations/document_loaders/glue_catalog/)\\n    - [Google AlloyDB for PostgreSQL](/docs/integrations/document_loaders/google_alloydb/)\\n    - [Google BigQuery](/docs/integrations/document_loaders/google_bigquery/)\\n    - [Google Bigtable](/docs/integrations/document_loaders/google_bigtable/)\\n    - [Google Cloud SQL for SQL server](/docs/integrations/document_loaders/google_cloud_sql_mssql/)\\n    - [Google Cloud SQL for MySQL](/docs/integrations/document_loaders/google_cloud_sql_mysql/)\\n    - [Google Cloud SQL for PostgreSQL](/docs/integrations/document_loaders/google_cloud_sql_pg/)\\n    - [Google Cloud Storage Directory](/docs/integrations/document_loaders/google_cloud_storage_directory/)\\n    - [Google Cloud Storage File](/docs/integrations/document_loaders/google_cloud_storage_file/)\\n    - [Google Firestore in Datastore Mode](/docs/integrations/document_loaders/google_datastore/)\\n    - [Google Drive](/docs/integrations/document_loaders/google_drive/)\\n    - [Google El Carro for Oracle Workloads](/docs/integrations/document_loaders/google_el_carro/)\\n    - [Google Firestore (Native Mode)](/docs/integrations/document_loaders/google_firestore/)\\n    - [Google Memorystore for Redis](/docs/integrations/document_loaders/google_memorystore_redis/)\\n    - [Google Spanner](/docs/integrations/document_loaders/google_spanner/)\\n    - [Google Speech-to-Text Audio Transcripts](/docs/integrations/document_loaders/google_speech_to_text/)\\n    - [Grobid](/docs/integrations/document_loaders/grobid/)\\n    - [Gutenberg](/docs/integrations/document_loaders/gutenberg/)\\n    - [Hacker News](/docs/integrations/document_loaders/hacker_news/)\\n    - [Huawei OBS Directory](/docs/integrations/document_loaders/huawei_obs_directory/)\\n    - [Huawei OBS File](/docs/integrations/document_loaders/huawei_obs_file/)\\n    - [HuggingFace dataset](/docs/integrations/document_loaders/hugging_face_dataset/)\\n    - [iFixit](/docs/integrations/document_loaders/ifixit/)\\n    - [Images](/docs/integrations/document_loaders/image/)\\n    - [Image captions](/docs/integrations/document_loaders/image_captions/)\\n    - [IMSDb](/docs/integrations/document_loaders/imsdb/)\\n    - [Iugu](/docs/integrations/document_loaders/iugu/)\\n    - [Joplin](/docs/integrations/document_loaders/joplin/)\\n    - [JSONLoader](/docs/integrations/document_loaders/json/)\\n    - [Jupyter Notebook](/docs/integrations/document_loaders/jupyter_notebook/)\\n    - [Kinetica](/docs/integrations/document_loaders/kinetica/)\\n    - [lakeFS](/docs/integrations/document_loaders/lakefs/)\\n    - [LangSmith](/docs/integrations/document_loaders/langsmith/)\\n    - [LarkSuite (FeiShu)](/docs/integrations/document_loaders/larksuite/)\\n    - [LLM Sherpa](/docs/integrations/document_loaders/llmsherpa/)\\n    - [Mastodon](/docs/integrations/document_loaders/mastodon/)\\n    - [MathPixPDFLoader](/docs/integrations/document_loaders/mathpix/)\\n    - [MediaWiki Dump](/docs/integrations/document_loaders/mediawikidump/)\\n    - [Merge Documents Loader](/docs/integrations/document_loaders/merge_doc/)\\n    - [mhtml](/docs/integrations/document_loaders/mhtml/)\\n    - [Microsoft Excel](/docs/integrations/document_loaders/microsoft_excel/)\\n    - [Microsoft OneDrive](/docs/integrations/document_loaders/microsoft_onedrive/)\\n    - [Microsoft OneNote](/docs/integrations/document_loaders/microsoft_onenote/)\\n    - [Microsoft PowerPoint](/docs/integrations/document_loaders/microsoft_powerpoint/)\\n    - [Microsoft SharePoint](/docs/integrations/document_loaders/microsoft_sharepoint/)\\n    - [Microsoft Word](/docs/integrations/document_loaders/microsoft_word/)\\n    - [Near Blockchain](/docs/integrations/document_loaders/mintbase/)\\n    - [Modern Treasury](/docs/integrations/document_loaders/modern_treasury/)\\n    - [MongoDB](/docs/integrations/document_loaders/mongodb/)\\n    - [News URL](/docs/integrations/document_loaders/news/)\\n    - [Notion DB 2/2](/docs/integrations/document_loaders/notion/)\\n    - [Nuclia](/docs/integrations/document_loaders/nuclia/)\\n    - [Obsidian](/docs/integrations/document_loaders/obsidian/)\\n    - [Open Document Format (ODT)](/docs/integrations/document_loaders/odt/)\\n    - [Open City Data](/docs/integrations/document_loaders/open_city_data/)\\n    - [Oracle Autonomous Database](/docs/integrations/document_loaders/oracleadb_loader/)\\n    - [Oracle AI Vector Search: Document Processing](/docs/integrations/document_loaders/oracleai/)\\n    - [Org-mode](/docs/integrations/document_loaders/org_mode/)\\n    - [Pandas DataFrame](/docs/integrations/document_loaders/pandas_dataframe/)\\n    - [PDFMiner](/docs/integrations/document_loaders/pdfminer/)\\n    - [PDFPlumber](/docs/integrations/document_loaders/pdfplumber/)\\n    - [Pebblo Safe DocumentLoader](/docs/integrations/document_loaders/pebblo/)\\n    - [Polars DataFrame](/docs/integrations/document_loaders/polars_dataframe/)\\n    - [Psychic](/docs/integrations/document_loaders/psychic/)\\n    - [PubMed](/docs/integrations/document_loaders/pubmed/)\\n    - [PyMuPDF](/docs/integrations/document_loaders/pymupdf/)\\n    - [PyPDFDirectoryLoader](/docs/integrations/document_loaders/pypdfdirectory/)\\n    - [PyPDFium2Loader](/docs/integrations/document_loaders/pypdfium2/)\\n    - [PyPDFLoader](/docs/integrations/document_loaders/pypdfloader/)\\n    - [PySpark](/docs/integrations/document_loaders/pyspark_dataframe/)\\n    - [Quip](/docs/integrations/document_loaders/quip/)\\n    - [ReadTheDocs Documentation](/docs/integrations/document_loaders/readthedocs_documentation/)\\n    - [Recursive URL](/docs/integrations/document_loaders/recursive_url/)\\n    - [Reddit](/docs/integrations/document_loaders/reddit/)\\n    - [Roam](/docs/integrations/document_loaders/roam/)\\n    - [Rockset](/docs/integrations/document_loaders/rockset/)\\n    - [rspace](/docs/integrations/document_loaders/rspace/)\\n    - [RSS Feeds](/docs/integrations/document_loaders/rss/)\\n    - [RST](/docs/integrations/document_loaders/rst/)\\n    - [scrapfly](/docs/integrations/document_loaders/scrapfly/)\\n    - [ScrapingAnt](/docs/integrations/document_loaders/scrapingant/)\\n    - [Sitemap](/docs/integrations/document_loaders/sitemap/)\\n    - [Slack](/docs/integrations/document_loaders/slack/)\\n    - [Snowflake](/docs/integrations/document_loaders/snowflake/)\\n    - [Source Code](/docs/integrations/document_loaders/source_code/)\\n    - [Spider](/docs/integrations/document_loaders/spider/)\\n    - [Spreedly](/docs/integrations/document_loaders/spreedly/)\\n    - [Stripe](/docs/integrations/document_loaders/stripe/)\\n    - [Subtitle](/docs/integrations/document_loaders/subtitle/)\\n    - [SurrealDB](/docs/integrations/document_loaders/surrealdb/)\\n    - [Telegram](/docs/integrations/document_loaders/telegram/)\\n    - [Tencent COS Directory](/docs/integrations/document_loaders/tencent_cos_directory/)\\n    - [Tencent COS File](/docs/integrations/document_loaders/tencent_cos_file/)\\n    - [TensorFlow Datasets](/docs/integrations/document_loaders/tensorflow_datasets/)\\n    - [TiDB](/docs/integrations/document_loaders/tidb/)\\n    - [2Markdown](/docs/integrations/document_loaders/tomarkdown/)\\n    - [TOML](/docs/integrations/document_loaders/toml/)\\n    - [Trello](/docs/integrations/document_loaders/trello/)\\n    - [TSV](/docs/integrations/document_loaders/tsv/)\\n    - [Twitter](/docs/integrations/document_loaders/twitter/)\\n    - [Unstructured](/docs/integrations/document_loaders/unstructured_file/)\\n    - [UnstructuredMarkdownLoader](/docs/integrations/document_loaders/unstructured_markdown/)\\n    - [UnstructuredPDFLoader](/docs/integrations/document_loaders/unstructured_pdfloader/)\\n    - [Upstage](/docs/integrations/document_loaders/upstage/)\\n    - [URL](/docs/integrations/document_loaders/url/)\\n    - [Vsdx](/docs/integrations/document_loaders/vsdx/)\\n    - [Weather](/docs/integrations/document_loaders/weather/)\\n    - [WebBaseLoader](/docs/integrations/document_loaders/web_base/)\\n    - [WhatsApp Chat](/docs/integrations/document_loaders/whatsapp_chat/)\\n    - [Wikipedia](/docs/integrations/document_loaders/wikipedia/)\\n    - [UnstructuredXMLLoader](/docs/integrations/document_loaders/xml/)\\n    - [Xorbits Pandas DataFrame](/docs/integrations/document_loaders/xorbits/)\\n    - [YouTube audio](/docs/integrations/document_loaders/youtube_audio/)\\n    - [YouTube transcripts](/docs/integrations/document_loaders/youtube_transcript/)\\n    - [Yuque](/docs/integrations/document_loaders/yuque/)\\n  - [Vector stores](/docs/integrations/vectorstores/)\\n\\n    - [Vectorstores](/docs/integrations/vectorstores/)\\n    - [Activeloop Deep Lake](/docs/integrations/vectorstores/activeloop_deeplake/)\\n    - [Aerospike](/docs/integrations/vectorstores/aerospike/)\\n    - [Alibaba Cloud OpenSearch](/docs/integrations/vectorstores/alibabacloud_opensearch/)\\n    - [AnalyticDB](/docs/integrations/vectorstores/analyticdb/)\\n    - [Annoy](/docs/integrations/vectorstores/annoy/)\\n    - [Apache Doris](/docs/integrations/vectorstores/apache_doris/)\\n    - [ApertureDB](/docs/integrations/vectorstores/aperturedb/)\\n    - [Astra DB Vector Store](/docs/integrations/vectorstores/astradb/)\\n    - [Atlas](/docs/integrations/vectorstores/atlas/)\\n    - [AwaDB](/docs/integrations/vectorstores/awadb/)\\n    - [Azure Cosmos DB Mongo vCore](/docs/integrations/vectorstores/azure_cosmos_db/)\\n    - [Azure Cosmos DB No SQL](/docs/integrations/vectorstores/azure_cosmos_db_no_sql/)\\n    - [Azure AI Search](/docs/integrations/vectorstores/azuresearch/)\\n    - [Bagel](/docs/integrations/vectorstores/bagel/)\\n    - [BagelDB](/docs/integrations/vectorstores/bageldb/)\\n    - [Baidu Cloud ElasticSearch VectorSearch](/docs/integrations/vectorstores/baiducloud_vector_search/)\\n    - [Baidu VectorDB](/docs/integrations/vectorstores/baiduvectordb/)\\n    - [Apache Cassandra](/docs/integrations/vectorstores/cassandra/)\\n    - [Chroma](/docs/integrations/vectorstores/chroma/)\\n    - [Clarifai](/docs/integrations/vectorstores/clarifai/)\\n    - [ClickHouse](/docs/integrations/vectorstores/clickhouse/)\\n    - [Couchbase](/docs/integrations/vectorstores/couchbase/)\\n    - [DashVector](/docs/integrations/vectorstores/dashvector/)\\n    - [Databricks](/docs/integrations/vectorstores/databricks_vector_search/)\\n    - [DingoDB](/docs/integrations/vectorstores/dingo/)\\n    - [DocArray HnswSearch](/docs/integrations/vectorstores/docarray_hnsw/)\\n    - [DocArray InMemorySearch](/docs/integrations/vectorstores/docarray_in_memory/)\\n    - [Amazon Document DB](/docs/integrations/vectorstores/documentdb/)\\n    - [DuckDB](/docs/integrations/vectorstores/duckdb/)\\n    - [China Mobile ECloud ElasticSearch VectorSearch](/docs/integrations/vectorstores/ecloud_vector_search/)\\n    - [Elasticsearch](/docs/integrations/vectorstores/elasticsearch/)\\n    - [Epsilla](/docs/integrations/vectorstores/epsilla/)\\n    - [Faiss](/docs/integrations/vectorstores/faiss/)\\n    - [Faiss (Async)](/docs/integrations/vectorstores/faiss_async/)\\n    - [Google AlloyDB for PostgreSQL](/docs/integrations/vectorstores/google_alloydb/)\\n    - [Google BigQuery Vector Search](/docs/integrations/vectorstores/google_bigquery_vector_search/)\\n    - [Google Cloud SQL for MySQL](/docs/integrations/vectorstores/google_cloud_sql_mysql/)\\n    - [Google Cloud SQL for PostgreSQL](/docs/integrations/vectorstores/google_cloud_sql_pg/)\\n    - [Firestore](/docs/integrations/vectorstores/google_firestore/)\\n    - [Google Memorystore for Redis](/docs/integrations/vectorstores/google_memorystore_redis/)\\n    - [Google Spanner](/docs/integrations/vectorstores/google_spanner/)\\n    - [Google Vertex AI Feature Store](/docs/integrations/vectorstores/google_vertex_ai_feature_store/)\\n    - [Google Vertex AI Vector Search](/docs/integrations/vectorstores/google_vertex_ai_vector_search/)\\n    - [Hippo](/docs/integrations/vectorstores/hippo/)\\n    - [Hologres](/docs/integrations/vectorstores/hologres/)\\n    - [Infinispan](/docs/integrations/vectorstores/infinispanvs/)\\n    - [Jaguar Vector Database](/docs/integrations/vectorstores/jaguar/)\\n    - [KDB.AI](/docs/integrations/vectorstores/kdbai/)\\n    - [Kinetica](/docs/integrations/vectorstores/kinetica/)\\n    - [LanceDB](/docs/integrations/vectorstores/lancedb/)\\n    - [Lantern](/docs/integrations/vectorstores/lantern/)\\n    - [LLMRails](/docs/integrations/vectorstores/llm_rails/)\\n    - [ManticoreSearch VectorStore](/docs/integrations/vectorstores/manticore_search/)\\n    - [Marqo](/docs/integrations/vectorstores/marqo/)\\n    - [Meilisearch](/docs/integrations/vectorstores/meilisearch/)\\n    - [Amazon MemoryDB](/docs/integrations/vectorstores/memorydb/)\\n    - [Milvus](/docs/integrations/vectorstores/milvus/)\\n    - [Momento Vector Index (MVI)](/docs/integrations/vectorstores/momento_vector_index/)\\n    - [MongoDB Atlas](/docs/integrations/vectorstores/mongodb_atlas/)\\n    - [MyScale](/docs/integrations/vectorstores/myscale/)\\n    - [Neo4j Vector Index](/docs/integrations/vectorstores/neo4jvector/)\\n    - [NucliaDB](/docs/integrations/vectorstores/nucliadb/)\\n    - [OpenSearch](/docs/integrations/vectorstores/opensearch/)\\n    - [Oracle AI Vector Search: Vector Store](/docs/integrations/vectorstores/oracle/)\\n    - [Pathway](/docs/integrations/vectorstores/pathway/)\\n    - [Postgres Embedding](/docs/integrations/vectorstores/pgembedding/)\\n    - [PGVecto.rs](/docs/integrations/vectorstores/pgvecto_rs/)\\n    - [PGVector](/docs/integrations/vectorstores/pgvector/)\\n    - [Pinecone](/docs/integrations/vectorstores/pinecone/)\\n    - [Qdrant](/docs/integrations/vectorstores/qdrant/)\\n    - [Redis](/docs/integrations/vectorstores/redis/)\\n    - [Relyt](/docs/integrations/vectorstores/relyt/)\\n    - [Rockset](/docs/integrations/vectorstores/rockset/)\\n    - [SAP HANA Cloud Vector Engine](/docs/integrations/vectorstores/sap_hanavector/)\\n    - [ScaNN](/docs/integrations/vectorstores/scann/)\\n    - [SemaDB](/docs/integrations/vectorstores/semadb/)\\n    - [SingleStoreDB](/docs/integrations/vectorstores/singlestoredb/)\\n    - [scikit-learn](/docs/integrations/vectorstores/sklearn/)\\n    - [SQLite-VSS](/docs/integrations/vectorstores/sqlitevss/)\\n    - [StarRocks](/docs/integrations/vectorstores/starrocks/)\\n    - [Supabase (Postgres)](/docs/integrations/vectorstores/supabase/)\\n    - [SurrealDB](/docs/integrations/vectorstores/surrealdb/)\\n    - [Tair](/docs/integrations/vectorstores/tair/)\\n    - [Tencent Cloud VectorDB](/docs/integrations/vectorstores/tencentvectordb/)\\n    - [ThirdAI NeuralDB](/docs/integrations/vectorstores/thirdai_neuraldb/)\\n    - [TiDB Vector](/docs/integrations/vectorstores/tidb_vector/)\\n    - [Tigris](/docs/integrations/vectorstores/tigris/)\\n    - [TileDB](/docs/integrations/vectorstores/tiledb/)\\n    - [Timescale Vector (Postgres)](/docs/integrations/vectorstores/timescalevector/)\\n    - [Typesense](/docs/integrations/vectorstores/typesense/)\\n    - [Upstash Vector](/docs/integrations/vectorstores/upstash/)\\n    - [USearch](/docs/integrations/vectorstores/usearch/)\\n    - [Vald](/docs/integrations/vectorstores/vald/)\\n    - [Intel\\'s Visual Data Management System (VDMS)](/docs/integrations/vectorstores/vdms/)\\n    - [Vearch](/docs/integrations/vectorstores/vearch/)\\n    - [Vectara](/docs/integrations/vectorstores/vectara/)\\n    - [Vespa](/docs/integrations/vectorstores/vespa/)\\n    - [viking DB](/docs/integrations/vectorstores/vikingdb/)\\n    - [vlite](/docs/integrations/vectorstores/vlite/)\\n    - [Weaviate](/docs/integrations/vectorstores/weaviate/)\\n    - [Xata](/docs/integrations/vectorstores/xata/)\\n    - [Yellowbrick](/docs/integrations/vectorstores/yellowbrick/)\\n    - [Zep](/docs/integrations/vectorstores/zep/)\\n    - [Zep Cloud](/docs/integrations/vectorstores/zep_cloud/)\\n    - [Zilliz](/docs/integrations/vectorstores/zilliz/)\\n  - [Retrievers](/docs/integrations/retrievers/)\\n\\n    - [Retrievers](/docs/integrations/retrievers/)\\n    - [Activeloop Deep Memory](/docs/integrations/retrievers/activeloop/)\\n    - [Amazon Kendra](/docs/integrations/retrievers/amazon_kendra_retriever/)\\n    - [Arcee](/docs/integrations/retrievers/arcee/)\\n    - [Arxiv](/docs/integrations/retrievers/arxiv/)\\n    - [AskNews](/docs/integrations/retrievers/asknews/)\\n    - [Azure AI Search](/docs/integrations/retrievers/azure_ai_search/)\\n    - [Bedrock (Knowledge Bases)](/docs/integrations/retrievers/bedrock/)\\n    - [BM25](/docs/integrations/retrievers/bm25/)\\n    - [Box](/docs/integrations/retrievers/box/)\\n    - [BREEBS (Open Knowledge)](/docs/integrations/retrievers/breebs/)\\n    - [Chaindesk](/docs/integrations/retrievers/chaindesk/)\\n    - [ChatGPT plugin](/docs/integrations/retrievers/chatgpt-plugin/)\\n    - [Cohere reranker](/docs/integrations/retrievers/cohere-reranker/)\\n    - [Cohere RAG](/docs/integrations/retrievers/cohere/)\\n    - [DocArray](/docs/integrations/retrievers/docarray_retriever/)\\n    - [Dria](/docs/integrations/retrievers/dria_index/)\\n    - [ElasticSearch BM25](/docs/integrations/retrievers/elastic_search_bm25/)\\n    - [Elasticsearch](/docs/integrations/retrievers/elasticsearch_retriever/)\\n    - [Embedchain](/docs/integrations/retrievers/embedchain/)\\n    - [FlashRank reranker](/docs/integrations/retrievers/flashrank-reranker/)\\n    - [Fleet AI Context](/docs/integrations/retrievers/fleet_context/)\\n    - [Google Drive](/docs/integrations/retrievers/google_drive/)\\n    - [Google Vertex AI Search](/docs/integrations/retrievers/google_vertex_ai_search/)\\n    - [JaguarDB Vector Database](/docs/integrations/retrievers/jaguar/)\\n    - [Kay.ai](/docs/integrations/retrievers/kay/)\\n    - [Kinetica Vectorstore based Retriever](/docs/integrations/retrievers/kinetica/)\\n    - [kNN](/docs/integrations/retrievers/knn/)\\n    - [LLMLingua Document Compressor](/docs/integrations/retrievers/llmlingua/)\\n    - [LOTR (Merger Retriever)](/docs/integrations/retrievers/merger_retriever/)\\n    - [Metal](/docs/integrations/retrievers/metal/)\\n    - [Milvus Hybrid Search](/docs/integrations/retrievers/milvus_hybrid_search/)\\n    - [NanoPQ (Product Quantization)](/docs/integrations/retrievers/nanopq/)\\n    - [Outline](/docs/integrations/retrievers/outline/)\\n    - [Pinecone Hybrid Search](/docs/integrations/retrievers/pinecone_hybrid_search/)\\n    - [PubMed](/docs/integrations/retrievers/pubmed/)\\n    - [Qdrant Sparse Vector](/docs/integrations/retrievers/qdrant-sparse/)\\n    - [RAGatouille](/docs/integrations/retrievers/ragatouille/)\\n    - [RePhraseQuery](/docs/integrations/retrievers/re_phrase/)\\n    - [Rememberizer](/docs/integrations/retrievers/rememberizer/)\\n    - [SEC filing](/docs/integrations/retrievers/sec_filings/)\\n    - [Self-querying retrievers](/docs/integrations/retrievers/self_query/)\\n\\n    - [SingleStoreDB](/docs/integrations/retrievers/singlestoredb/)\\n    - [SVM](/docs/integrations/retrievers/svm/)\\n    - [TavilySearchAPI](/docs/integrations/retrievers/tavily/)\\n    - [TF-IDF](/docs/integrations/retrievers/tf_idf/)\\n    - [\\\\*\\\\*NeuralDB\\\\*\\\\*](/docs/integrations/retrievers/thirdai_neuraldb/)\\n    - [Vespa](/docs/integrations/retrievers/vespa/)\\n    - [Weaviate Hybrid Search](/docs/integrations/retrievers/weaviate-hybrid/)\\n    - [Wikipedia](/docs/integrations/retrievers/wikipedia/)\\n    - [You.com](/docs/integrations/retrievers/you-retriever/)\\n    - [Zep Cloud](/docs/integrations/retrievers/zep_cloud_memorystore/)\\n    - [Zep Open Source](/docs/integrations/retrievers/zep_memorystore/)\\n    - [Zilliz Cloud Pipeline](/docs/integrations/retrievers/zilliz_cloud_pipeline/)\\n  - [Tools/Toolkits](/docs/integrations/tools/)\\n\\n    - [Tools](/docs/integrations/tools/)\\n    - [AINetwork Toolkit](/docs/integrations/tools/ainetwork/)\\n    - [Alpha Vantage](/docs/integrations/tools/alpha_vantage/)\\n    - [Amadeus Toolkit](/docs/integrations/tools/amadeus/)\\n    - [ArXiv](/docs/integrations/tools/arxiv/)\\n    - [AskNews](/docs/integrations/tools/asknews/)\\n    - [AWS Lambda](/docs/integrations/tools/awslambda/)\\n    - [Azure AI Services Toolkit](/docs/integrations/tools/azure_ai_services/)\\n    - [Azure Cognitive Services Toolkit](/docs/integrations/tools/azure_cognitive_services/)\\n    - [Azure Container Apps dynamic sessions](/docs/integrations/tools/azure_dynamic_sessions/)\\n    - [Shell (bash)](/docs/integrations/tools/bash/)\\n    - [Bearly Code Interpreter](/docs/integrations/tools/bearly/)\\n    - [Bing Search](/docs/integrations/tools/bing_search/)\\n    - [Brave Search](/docs/integrations/tools/brave_search/)\\n    - [Cassandra Database Toolkit](/docs/integrations/tools/cassandra_database/)\\n    - [ChatGPT Plugins](/docs/integrations/tools/chatgpt_plugins/)\\n    - [ClickUp Toolkit](/docs/integrations/tools/clickup/)\\n    - [Cogniswitch Toolkit](/docs/integrations/tools/cogniswitch/)\\n    - [Connery Toolkit and Tools](/docs/integrations/tools/connery/)\\n    - [Dall-E Image Generator](/docs/integrations/tools/dalle_image_generator/)\\n    - [Databricks Unity Catalog (UC)](/docs/integrations/tools/databricks/)\\n    - [DataForSEO](/docs/integrations/tools/dataforseo/)\\n    - [Dataherald](/docs/integrations/tools/dataherald/)\\n    - [DuckDuckGo Search](/docs/integrations/tools/ddg/)\\n    - [E2B Data Analysis](/docs/integrations/tools/e2b_data_analysis/)\\n    - [Eden AI](/docs/integrations/tools/edenai_tools/)\\n    - [Eleven Labs Text2Speech](/docs/integrations/tools/eleven_labs_tts/)\\n    - [Exa Search](/docs/integrations/tools/exa_search/)\\n    - [File System](/docs/integrations/tools/filesystem/)\\n    - [FinancialDatasets Toolkit](/docs/integrations/tools/financial_datasets/)\\n    - [Github Toolkit](/docs/integrations/tools/github/)\\n    - [Gitlab Toolkit](/docs/integrations/tools/gitlab/)\\n    - [Gmail Toolkit](/docs/integrations/tools/gmail/)\\n    - [Golden Query](/docs/integrations/tools/golden_query/)\\n    - [Google Cloud Text-to-Speech](/docs/integrations/tools/google_cloud_texttospeech/)\\n    - [Google Drive](/docs/integrations/tools/google_drive/)\\n    - [Google Finance](/docs/integrations/tools/google_finance/)\\n    - [Google Imagen](/docs/integrations/tools/google_imagen/)\\n    - [Google Jobs](/docs/integrations/tools/google_jobs/)\\n    - [Google Lens](/docs/integrations/tools/google_lens/)\\n    - [Google Places](/docs/integrations/tools/google_places/)\\n    - [Google Scholar](/docs/integrations/tools/google_scholar/)\\n    - [Google Search](/docs/integrations/tools/google_search/)\\n    - [Google Serper](/docs/integrations/tools/google_serper/)\\n    - [Google Trends](/docs/integrations/tools/google_trends/)\\n    - [Gradio](/docs/integrations/tools/gradio_tools/)\\n    - [GraphQL](/docs/integrations/tools/graphql/)\\n    - [HuggingFace Hub Tools](/docs/integrations/tools/huggingface_tools/)\\n    - [Human as a tool](/docs/integrations/tools/human_tools/)\\n    - [IFTTT WebHooks](/docs/integrations/tools/ifttt/)\\n    - [Infobip](/docs/integrations/tools/infobip/)\\n    - [Ionic Shopping Tool](/docs/integrations/tools/ionic_shopping/)\\n    - [Jina Search](/docs/integrations/tools/jina_search/)\\n    - [Jira Toolkit](/docs/integrations/tools/jira/)\\n    - [JSON Toolkit](/docs/integrations/tools/json/)\\n    - [Lemon Agent](/docs/integrations/tools/lemonai/)\\n    - [Memorize](/docs/integrations/tools/memorize/)\\n    - [Mojeek Search](/docs/integrations/tools/mojeek_search/)\\n    - [MultiOn Toolkit](/docs/integrations/tools/multion/)\\n    - [NASA Toolkit](/docs/integrations/tools/nasa/)\\n    - [Nuclia Understanding](/docs/integrations/tools/nuclia/)\\n    - [NVIDIA Riva: ASR and TTS](/docs/integrations/tools/nvidia_riva/)\\n    - [Office365 Toolkit](/docs/integrations/tools/office365/)\\n    - [OpenAPI Toolkit](/docs/integrations/tools/openapi/)\\n    - [Natural Language API Toolkits](/docs/integrations/tools/openapi_nla/)\\n    - [OpenWeatherMap](/docs/integrations/tools/openweathermap/)\\n    - [Oracle AI Vector Search: Generate Summary](/docs/integrations/tools/oracleai/)\\n    - [Pandas Dataframe](/docs/integrations/tools/pandas/)\\n    - [Passio NutritionAI](/docs/integrations/tools/passio_nutrition_ai/)\\n    - [PlayWright Browser Toolkit](/docs/integrations/tools/playwright/)\\n    - [Polygon IO Toolkit and Tools](/docs/integrations/tools/polygon/)\\n    - [PowerBI Toolkit](/docs/integrations/tools/powerbi/)\\n    - [PubMed](/docs/integrations/tools/pubmed/)\\n    - [Python REPL](/docs/integrations/tools/python/)\\n    - [Reddit Search](/docs/integrations/tools/reddit_search/)\\n    - [Requests Toolkit](/docs/integrations/tools/requests/)\\n    - [Riza Code Interpreter](/docs/integrations/tools/riza/)\\n    - [Robocorp Toolkit](/docs/integrations/tools/robocorp/)\\n    - [SceneXplain](/docs/integrations/tools/sceneXplain/)\\n    - [SearchApi](/docs/integrations/tools/searchapi/)\\n    - [SearxNG Search](/docs/integrations/tools/searx_search/)\\n    - [Semantic Scholar API Tool](/docs/integrations/tools/semanticscholar/)\\n    - [SerpAPI](/docs/integrations/tools/serpapi/)\\n    - [Slack Toolkit](/docs/integrations/tools/slack/)\\n    - [Spark SQL Toolkit](/docs/integrations/tools/spark_sql/)\\n    - [SQLDatabase Toolkit](/docs/integrations/tools/sql_database/)\\n    - [StackExchange](/docs/integrations/tools/stackexchange/)\\n    - [Steam Toolkit](/docs/integrations/tools/steam/)\\n    - [Tavily Search](/docs/integrations/tools/tavily_search/)\\n    - [Twilio](/docs/integrations/tools/twilio/)\\n    - [Upstage](/docs/integrations/tools/upstage_groundedness_check/)\\n    - [Wikidata](/docs/integrations/tools/wikidata/)\\n    - [Wikipedia](/docs/integrations/tools/wikipedia/)\\n    - [Wolfram Alpha](/docs/integrations/tools/wolfram_alpha/)\\n    - [Yahoo Finance News](/docs/integrations/tools/yahoo_finance_news/)\\n    - [You.com Search](/docs/integrations/tools/you/)\\n    - [YouTube](/docs/integrations/tools/youtube/)\\n    - [Zapier Natural Language Actions](/docs/integrations/tools/zapier/)\\n    - [ZenGuard AI](/docs/integrations/tools/zenguard/)\\n  - [Key-value stores](/docs/integrations/stores/)\\n\\n    - [AstraDB](/docs/integrations/stores/astradb/)\\n    - [Cassandra](/docs/integrations/stores/cassandra/)\\n    - [Elasticsearch](/docs/integrations/stores/elasticsearch/)\\n    - [Local Filesystem](/docs/integrations/stores/file_system/)\\n    - [In-memory](/docs/integrations/stores/in_memory/)\\n    - [Key-value stores](/docs/integrations/stores/)\\n    - [Redis](/docs/integrations/stores/redis/)\\n    - [Upstash Redis](/docs/integrations/stores/upstash_redis/)\\n  - Other\\n\\n- [Home page](/)\\n- [Components](/docs/integrations/components/)\\n- [Document loaders](/docs/integrations/document_loaders/)\\n- FireCrawl\\n\\nOn this page\\n\\n# FireCrawl\\n\\n[FireCrawl](https://firecrawl.dev/?ref=langchain) crawls and convert any website into LLM-ready data. It crawls all accessible subpages and give you clean markdown and metadata for each. No sitemap required.\\n\\nFireCrawl handles complex tasks such as reverse proxies, caching, rate limits, and content blocked by JavaScript. Built by the [mendable.ai](https://mendable.ai) team.\\n\\n## Overview [\\u200b](\\\\#overview \"Direct link to Overview\")\\n\\n### Integration details [\\u200b](\\\\#integration-details \"Direct link to Integration details\")\\n\\n| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl/) |\\n| :-- | :-- | :-: | :-: | :-: |\\n| [FireCrawlLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html) | [langchain\\\\_community](https://python.langchain.com/api_reference/community/index.html) | ‚úÖ | ‚ùå | ‚úÖ |\\n\\n### Loader features [\\u200b](\\\\#loader-features \"Direct link to Loader features\")\\n\\n| Source | Document Lazy Loading | Native Async Support |\\n| :-: | :-: | :-: |\\n| FireCrawlLoader | ‚úÖ | ‚ùå |\\n\\n## Setup [\\u200b](\\\\#setup \"Direct link to Setup\")\\n\\n### Credentials [\\u200b](\\\\#credentials \"Direct link to Credentials\")\\n\\nYou will need to get your own API key. Go to [this page](https://firecrawl.dev) to learn more.\\n\\n```codeBlockLines_e6Vv\\nimport getpass\\nimport os\\n\\nif \"FIRECRAWL_API_KEY\" not in os.environ:\\n    os.environ[\"FIRECRAWL_API_KEY\"] = getpass.getpass(\"Enter your Firecrawl API key: \")\\n\\n```\\n\\n### Installation [\\u200b](\\\\#installation \"Direct link to Installation\")\\n\\nYou will need to install both the `langchain_community` and `firecrawl-py` pacakges:\\n\\n```codeBlockLines_e6Vv\\n%pip install -qU firecrawl-py==0.0.20 langchain_community\\n\\n```\\n\\n## Initialization [\\u200b](\\\\#initialization \"Direct link to Initialization\")\\n\\n### Modes [\\u200b](\\\\#modes \"Direct link to Modes\")\\n\\n- `scrape`: Scrape single url and return the markdown.\\n- `crawl`: Crawl the url and all accessible sub pages and return the markdown for each one.\\n\\n```codeBlockLines_e6Vv\\nfrom langchain_community.document_loaders import FireCrawlLoader\\n\\nloader = FireCrawlLoader(url=\"https://firecrawl.dev\", mode=\"crawl\")\\n\\n```\\n\\n**API Reference:** [FireCrawlLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html)\\n\\n## Load [\\u200b](\\\\#load \"Direct link to Load\")\\n\\n```codeBlockLines_e6Vv\\ndocs = loader.load()\\n\\ndocs[0]\\n\\n```\\n\\n```codeBlockLines_e6Vv\\nDocument(metadata={\\'ogUrl\\': \\'https://www.firecrawl.dev/\\', \\'title\\': \\'Home - Firecrawl\\', \\'robots\\': \\'follow, index\\', \\'ogImage\\': \\'https://www.firecrawl.dev/og.png?123\\', \\'ogTitle\\': \\'Firecrawl\\', \\'sitemap\\': {\\'lastmod\\': \\'2024-08-12T00:28:16.681Z\\', \\'changefreq\\': \\'weekly\\'}, \\'keywords\\': \\'Firecrawl,Markdown,Data,Mendable,Langchain\\', \\'sourceURL\\': \\'https://www.firecrawl.dev/\\', \\'ogSiteName\\': \\'Firecrawl\\', \\'description\\': \\'Firecrawl crawls and converts any website into clean markdown.\\', \\'ogDescription\\': \\'Turn any website into LLM-ready data.\\', \\'pageStatusCode\\': 200, \\'ogLocaleAlternate\\': []}, page_content=\\'Introducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\\\n Join the waitlist to turn any website into an API with AI\\\\n\\\\n\\\\n\\\\n[üî• Firecrawl](/)\\\\n\\\\n*   [Playground](/playground)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](/blog)\\\\n    \\\\n*   Beta Features\\\\n\\\\n[Log In](/signin)\\\\n[Log In](/signin)\\\\n[Sign Up](/signin/signup)\\\\n 8.9k\\\\n\\\\n[üí• Get 2 months free with yearly plan](/pricing)\\\\n\\\\nTurn websites into  \\\\n_LLM-ready_ data\\\\n=====================================\\\\n\\\\nPower your AI apps with clean data crawled from any website. It\\\\\\'s also open-source.\\\\n\\\\nStart for free (500 credits)Start for free[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nA product by\\\\n\\\\n[![Mendable Logo](https://www.firecrawl.dev/images/mendable_logo_transparent.png)Mendable](https://mendable.ai)\\\\n\\\\n![Example Webpage](https://www.firecrawl.dev/multiple-websites.png)\\\\n\\\\nCrawl, Scrape, Clean\\\\n--------------------\\\\n\\\\nWe crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\\\n\\\\n    \\\\n      [\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \"url\": \"https://www.firecrawl.dev/\",\\\\\\\\\\\\n          \"markdown\": \"## Welcome to Firecrawl\\\\\\\\\\\\n            Firecrawl is a web scraper that allows you to extract the content of a webpage.\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \"url\": \"https://www.firecrawl.dev/features\",\\\\\\\\\\\\n          \"markdown\": \"## Features\\\\\\\\\\\\n            Discover how Firecrawl\\\\\\'s cutting-edge features can \\\\\\\\\\\\n            transform your data operations.\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \"url\": \"https://www.firecrawl.dev/pricing\",\\\\\\\\\\\\n          \"markdown\": \"## Pricing Plans\\\\\\\\\\\\n            Choose the perfect plan that fits your needs.\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \"url\": \"https://www.firecrawl.dev/about\",\\\\\\\\\\\\n          \"markdown\": \"## About Us\\\\\\\\\\\\n            Learn more about Firecrawl\\\\\\'s mission and the \\\\\\\\\\\\n            team behind our innovative platform.\"\\\\\\\\\\\\n        }\\\\\\\\\\\\n      ]\\\\n      \\\\n\\\\nNote: The markdown has been edited for display purposes.\\\\n\\\\nTrusted by Top Companies\\\\n------------------------\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/zapier.png)](https://www.zapier.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/gamma.svg)](https://gamma.app)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nvidia-com.png)](https://www.nvidia.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/teller-io.svg)](https://www.teller.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/stackai.svg)](https://www.stack-ai.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/palladiumdigital-co-uk.svg)](https://www.palladiumdigital.co.uk)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/worldwide-casting-com.svg)](https://www.worldwide-casting.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/open-gov-sg.png)](https://www.open.gov.sg)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/bain-com.svg)](https://www.bain.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/demand-io.svg)](https://www.demand.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nocodegarden-io.png)](https://www.nocodegarden.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/cyberagent-co-jp.svg)](https://www.cyberagent.co.jp)\\\\n\\\\nIntegrate today\\\\n---------------\\\\n\\\\nEnhance your applications with top-tier web scraping and crawling capabilities.\\\\n\\\\n#### Scrape\\\\n\\\\nExtract markdown or structured data from websites quickly and efficiently.\\\\n\\\\n#### Crawling\\\\n\\\\nNavigate and retrieve data from all accessible subpages, even without a sitemap.\\\\n\\\\nNode.js\\\\n\\\\nPython\\\\n\\\\ncURL\\\\n\\\\n1\\\\n\\\\n2\\\\n\\\\n3\\\\n\\\\n4\\\\n\\\\n5\\\\n\\\\n6\\\\n\\\\n7\\\\n\\\\n8\\\\n\\\\n9\\\\n\\\\n10\\\\n\\\\n// npm install @mendable/firecrawl-js  \\\\n  \\\\nimport FirecrawlApp from \\\\\\'@mendable/firecrawl-js\\\\\\';  \\\\n  \\\\nconst app \\\\\\\\= new FirecrawlApp({ apiKey: \"fc-YOUR\\\\\\\\_API\\\\\\\\_KEY\" });  \\\\n  \\\\n// Scrape a website:  \\\\nconst scrapeResult \\\\\\\\= await app.scrapeUrl(\\\\\\'firecrawl.dev\\\\\\');  \\\\n  \\\\nconsole.log(scrapeResult.data.markdown)\\\\n\\\\n#### Use well-known tools\\\\n\\\\nAlready fully integrated with the greatest existing tools and workflows.\\\\n\\\\n[![LlamaIndex](https://www.firecrawl.dev/logos/llamaindex.svg)](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-firecrawl-reader/)\\\\n[![Langchain](https://www.firecrawl.dev/integrations/langchain.png)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/logos/dify.png)](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/integrations/langflow_2.png)](https://www.langflow.org/)\\\\n[![Flowise](https://www.firecrawl.dev/integrations/flowise.png)](https://flowiseai.com/)\\\\n[![CrewAI](https://www.firecrawl.dev/integrations/crewai.png)](https://crewai.com/)\\\\n\\\\n#### Start for free, scale easily\\\\n\\\\nKick off your journey for free and scale seamlessly as your project expands.\\\\n\\\\n[Try it out](/signin/signup)\\\\n\\\\n#### Open-source\\\\n\\\\nDeveloped transparently and collaboratively. Join our community of contributors.\\\\n\\\\n[Check out our repo](https://github.com/mendableai/firecrawl)\\\\n\\\\nWe handle the hard stuff\\\\n------------------------\\\\n\\\\nRotating proxies, caching, rate limits, js-blocked content and more\\\\n\\\\n#### Crawling\\\\n\\\\nFirecrawl crawls all accessible subpages, even without a sitemap.\\\\n\\\\n#### Dynamic content\\\\n\\\\nFirecrawl gathers data even if a website uses javascript to render content.\\\\n\\\\n#### To Markdown\\\\n\\\\nFirecrawl returns clean, well formatted markdown - ready for use in LLM applications\\\\n\\\\n#### Crawling Orchestration\\\\n\\\\nFirecrawl orchestrates the crawling process in parallel for the fastest results.\\\\n\\\\n#### Caching\\\\n\\\\nFirecrawl caches content, so you don\\\\\\'t have to wait for a full scrape unless new content exists.\\\\n\\\\n#### Built for AI\\\\n\\\\nBuilt by LLM engineers, for LLM engineers. Giving you clean data the way you want it.\\\\n\\\\nOur wall of love\\\\n\\\\nDon\\\\\\'t take our word for it\\\\n--------------------------\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. üëè\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome üî• Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\\\'t recommend them enough.\\\\n\\\\n![latentsauce üßòüèΩ](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce üßòüèΩ\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. üëè\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome üî• Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\\\'t recommend them enough.\\\\n\\\\n![latentsauce üßòüèΩ](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce üßòüèΩ\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman üñáÔ∏è](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman üñáÔ∏è\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman üñáÔ∏è](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman üñáÔ∏è\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\nFlexible Pricing\\\\n----------------\\\\n\\\\nStart for free, then scale as you grow\\\\n\\\\nYearly (17% off)Yearly (2 months free)Monthly\\\\n\\\\nFree Plan\\\\n---------\\\\n\\\\n500 credits\\\\n\\\\n$0/month\\\\n\\\\n*   Scrape 500 pages\\\\n*   5 /scrape per min\\\\n*   1 /crawl per min\\\\n\\\\nGet Started\\\\n\\\\nHobby\\\\n-----\\\\n\\\\n3,000 credits\\\\n\\\\n$16/month\\\\n\\\\n*   Scrape 3,000 pages\\\\n*   10 /scrape per min\\\\n*   3 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nStandardMost Popular\\\\n--------------------\\\\n\\\\n100,000 credits\\\\n\\\\n$83/month\\\\n\\\\n*   Scrape 100,000 pages\\\\n*   50 /scrape per min\\\\n*   10 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nGrowth\\\\n------\\\\n\\\\n500,000 credits\\\\n\\\\n$333/month\\\\n\\\\n*   Scrape 500,000 pages\\\\n*   500 /scrape per min\\\\n*   50 /crawl per min\\\\n*   Priority Support\\\\n\\\\nSubscribe\\\\n\\\\nEnterprise Plan\\\\n---------------\\\\n\\\\nUnlimited credits. Custom RPMs.\\\\n\\\\nTalk to us\\\\n\\\\n*   Top priority support\\\\n*   Feature Acceleration\\\\n*   SLAs\\\\n*   Account Manager\\\\n*   Custom rate limits volume\\\\n*   Custom concurrency limits\\\\n*   Beta features access\\\\n*   CEO\\\\\\'s number\\\\n\\\\n\\\\\\\\* a /scrape refers to the [scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\\\n API endpoint.\\\\n\\\\n\\\\\\\\* a /crawl refers to the [crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl)\\\\n API endpoint.\\\\n\\\\nScrape Credits\\\\n--------------\\\\n\\\\nScrape credits are consumed for each API request, varying by endpoint and feature.\\\\n\\\\n| Features | Credits per page |\\\\n| --- | --- |\\\\n| Scrape(/scrape) | 1   |\\\\n| Crawl(/crawl) | 1   |\\\\n| Search(/search) | 1   |\\\\n| Scrape + LLM extraction (/scrape) | 50  |\\\\n\\\\n[üî•](/)\\\\n\\\\nReady to _Build?_\\\\n-----------------\\\\n\\\\nStart scraping web data for your AI apps today.  \\\\nNo credit card needed.\\\\n\\\\n[Get Started](/signin)\\\\n\\\\n[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nFAQ\\\\n---\\\\n\\\\nFrequently asked questions about Firecrawl\\\\n\\\\n#### General\\\\n\\\\nWhat is Firecrawl?\\\\n\\\\nFirecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data.\\\\n\\\\nWhat sites work?\\\\n\\\\nFirecrawl is best suited for business websites, docs and help centers. We currently don\\\\\\'t support social media platforms.\\\\n\\\\nWho can benefit from using Firecrawl?\\\\n\\\\nFirecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.\\\\n\\\\nIs Firecrawl open-source?\\\\n\\\\nYes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.\\\\n\\\\n#### Scraping & Crawling\\\\n\\\\nHow does Firecrawl handle dynamic content on websites?\\\\n\\\\nUnlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.\\\\n\\\\nWhy is it not crawling all the pages?\\\\n\\\\nThere are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you\\\\\\'re experiencing issues with the crawler, please reach out to our support team at hello@firecrawl.com.\\\\n\\\\nCan Firecrawl crawl websites without a sitemap?\\\\n\\\\nYes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.\\\\n\\\\nWhat formats can Firecrawl convert web data into?\\\\n\\\\nFirecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.\\\\n\\\\nHow does Firecrawl ensure the cleanliness of the data?\\\\n\\\\nFirecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.\\\\n\\\\nIs Firecrawl suitable for large-scale data scraping projects?\\\\n\\\\nAbsolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it\\\\\\'s designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.\\\\n\\\\nDoes it respect robots.txt?\\\\n\\\\nYes, Firecrawl crawler respects the rules set in a website\\\\\\'s robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler\\\\\\'s behavior. Firecrawl user agent name is \\\\\\'FirecrawlAgent\\\\\\'. If you notice any behavior that is not expected, please let us know at hello@firecrawl.com.\\\\n\\\\nWhat measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\\\\n\\\\nFirecrawl is built to navigate common web scraping challenges, including reverse proxies, rate limits, and caching. It smartly manages requests and employs caching techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.\\\\n\\\\nDoes Firecrawl handle captcha or authentication?\\\\n\\\\nFirecrawl avoids captcha by using stealth proxyies. When it encounters captcha, it attempts to solve it automatically, but this is not always possible. We are working to add support for more captcha solving methods. Firecrawl can handle authentication by providing auth headers to the API.\\\\n\\\\n#### API Related\\\\n\\\\nWhere can I find my API key?\\\\n\\\\nClick on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.\\\\n\\\\n#### Billing\\\\n\\\\nIs Firecrawl free?\\\\n\\\\nFirecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Standard or Scale plans for more credits.\\\\n\\\\nIs there a pay per use plan instead of monthly?\\\\n\\\\nNo we do not currently offer a pay per use plan, instead you can upgrade to our Standard or Growth plans for more credits and higher rate limits.\\\\n\\\\nHow many credit does scraping, crawling, and extraction cost?\\\\n\\\\nScraping costs 1 credit per page. Crawling costs 1 credit per page.\\\\n\\\\nDo you charge for failed requests (scrape, crawl, extract)?\\\\n\\\\nWe do not charge for any failed requests (scrape, crawl, extract). Please contact support at help@firecrawl.dev if you have any questions.\\\\n\\\\nWhat payment methods do you accept?\\\\n\\\\nWe accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.\\\\n\\\\n[üî•](/)\\\\n\\\\n¬© A product by Mendable.ai - All rights reserved.\\\\n\\\\n[StatusStatus](https://firecrawl.betteruptime.com)\\\\n[Terms of ServiceTerms of Service](/terms-of-service)\\\\n[Privacy PolicyPrivacy Policy](/privacy-policy)\\\\n\\\\n[Twitter](https://twitter.com/mendableai)\\\\n[GitHub](https://github.com/mendableai)\\\\n[Discord](https://discord.gg/gSmWdAkdwd)\\\\n\\\\n###### Helpful Links\\\\n\\\\n*   [Status](https://firecrawl.betteruptime.com/)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](https://www.firecrawl.dev/blog)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n\\\\nBacked by![Y Combinator Logo](https://www.firecrawl.dev/images/yc.svg)\\\\n\\\\n![SOC 2 Type II](https://www.firecrawl.dev/soc2type2badge.png)\\\\n\\\\n###### Resources\\\\n\\\\n*   [Community](#0)\\\\n    \\\\n*   [Terms of service](#0)\\\\n    \\\\n*   [Collaboration features](#0)\\\\n    \\\\n\\\\n###### Legals\\\\n\\\\n*   [Refund policy](#0)\\\\n    \\\\n*   [Terms & Conditions](#0)\\\\n    \\\\n*   [Privacy policy](#0)\\\\n    \\\\n*   [Brand Kit](#0)\\')\\n\\n```\\n\\n```codeBlockLines_e6Vv\\nprint(docs[0].metadata)\\n\\n```\\n\\n```codeBlockLines_e6Vv\\n{\\'ogUrl\\': \\'https://www.firecrawl.dev/\\', \\'title\\': \\'Home - Firecrawl\\', \\'robots\\': \\'follow, index\\', \\'ogImage\\': \\'https://www.firecrawl.dev/og.png?123\\', \\'ogTitle\\': \\'Firecrawl\\', \\'sitemap\\': {\\'lastmod\\': \\'2024-08-12T00:28:16.681Z\\', \\'changefreq\\': \\'weekly\\'}, \\'keywords\\': \\'Firecrawl,Markdown,Data,Mendable,Langchain\\', \\'sourceURL\\': \\'https://www.firecrawl.dev/\\', \\'ogSiteName\\': \\'Firecrawl\\', \\'description\\': \\'Firecrawl crawls and converts any website into clean markdown.\\', \\'ogDescription\\': \\'Turn any website into LLM-ready data.\\', \\'pageStatusCode\\': 200, \\'ogLocaleAlternate\\': []}\\n\\n```\\n\\n## Lazy Load [\\u200b](\\\\#lazy-load \"Direct link to Lazy Load\")\\n\\nYou can use lazy loading to minimize memory requirements.\\n\\n```codeBlockLines_e6Vv\\npages = []\\nfor doc in loader.lazy_load():\\n    pages.append(doc)\\n    if len(pages) >= 10:\\n        # do some paged operation, e.g.\\n        # index.upsert(page)\\n\\n        pages = []\\n\\n```\\n\\n```codeBlockLines_e6Vv\\nlen(pages)\\n\\n```\\n\\n```codeBlockLines_e6Vv\\n8\\n\\n```\\n\\n```codeBlockLines_e6Vv\\nprint(pages[0].page_content[:100])\\nprint(pages[0].metadata)\\n\\n```\\n\\n```codeBlockLines_e6Vv\\nIntroducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\n Join the waitlist to turn any web\\n{\\'ogUrl\\': \\'https://www.firecrawl.dev/blog/introducing-fire-engine-for-firecrawl\\', \\'title\\': \\'Introducing Fire Engine for Firecrawl\\', \\'robots\\': \\'follow, index\\', \\'ogImage\\': \\'https://www.firecrawl.dev/images/blog/fire-engine-launch.png\\', \\'ogTitle\\': \\'Introducing Fire Engine for Firecrawl\\', \\'sitemap\\': {\\'lastmod\\': \\'2024-08-06T00:00:00.000Z\\', \\'changefreq\\': \\'weekly\\'}, \\'keywords\\': \\'firecrawl,fireengine,web crawling,dashboard,web scraping,LLM,data extraction\\', \\'sourceURL\\': \\'https://www.firecrawl.dev/blog/introducing-fire-engine-for-firecrawl\\', \\'ogSiteName\\': \\'Firecrawl\\', \\'description\\': \\'The most scalable, reliable, and fast way to get web data for Firecrawl.\\', \\'ogDescription\\': \\'The most scalable, reliable, and fast way to get web data for Firecrawl.\\', \\'pageStatusCode\\': 200, \\'ogLocaleAlternate\\': []}\\n\\n```\\n\\n## Crawler Options [\\u200b](\\\\#crawler-options \"Direct link to Crawler Options\")\\n\\nYou can also pass `params` to the loader. This is a dictionary of options to pass to the crawler. See the [FireCrawl API documentation](https://github.com/mendableai/firecrawl-py) for more information.\\n\\n## API reference [\\u200b](\\\\#api-reference \"Direct link to API reference\")\\n\\nFor detailed documentation of all `FireCrawlLoader` features and configurations head to the API reference: [https://python.langchain.com/api\\\\_reference/community/document\\\\_loaders/langchain\\\\_community.document\\\\_loaders.firecrawl.FireCrawlLoader.html](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html)\\n\\n## Related [\\u200b](\\\\#related \"Direct link to Related\")\\n\\n- Document loader [conceptual guide](/docs/concepts/#document-loaders)\\n- Document loader [how-to guides](/docs/how_to/#document-loaders)\\n\\n[Edit this page](https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/document_loaders/firecrawl.ipynb)\\n\\n* * *\\n\\n#### Was this page helpful?\\n\\n#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchain/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CIssue+related+to+/docs/integrations/document_loaders/firecrawl/%3E&url=https://python.langchain.com/docs/integrations/document_loaders/firecrawl/).\\n\\n[Previous\\\\\\\\\\n\\\\\\\\\\nFigma](/docs/integrations/document_loaders/figma/) [Next\\\\\\\\\\n\\\\\\\\\\nGeopandas](/docs/integrations/document_loaders/geopandas/)\\n\\n- [Overview](#overview)\\n  - [Integration details](#integration-details)\\n  - [Loader features](#loader-features)\\n- [Setup](#setup)\\n  - [Credentials](#credentials)\\n  - [Installation](#installation)\\n- [Initialization](#initialization)\\n  - [Modes](#modes)\\n- [Load](#load)\\n- [Lazy Load](#lazy-load)\\n- [Crawler Options](#crawler-options)\\n- [API reference](#api-reference)\\n- [Related](#related)\\n\\nCommunity\\n\\n- [Twitter](https://twitter.com/LangChainAI)\\n\\nGitHub\\n\\n- [Organization](https://github.com/langchain-ai)\\n- [Python](https://github.com/langchain-ai/langchain)\\n- [JS/TS](https://github.com/langchain-ai/langchainjs)\\n\\nMore\\n\\n- [Homepage](https://langchain.com)\\n- [Blog](https://blog.langchain.dev)\\n- [YouTube](https://www.youtube.com/@LangChain)\\n\\nCopyright ¬© 2024 LangChain, Inc.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "a = StrOutputParser()\n",
    "\n",
    "a.parse(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 quiz questions based on the provided LangChain documentation:\n",
      "\n",
      "**Question 1**\n",
      "\n",
      "What is LangChain primarily designed for?\n",
      "\n",
      "a) Building blockchain applications.\n",
      "b) Developing applications powered by large language models (LLMs). \n",
      "c) Creating and managing cryptocurrency wallets.\n",
      "d) Designing and training machine learning models from scratch.\n",
      "\n",
      "**Answer: b)**\n",
      "\n",
      "**Question 2**\n",
      "\n",
      "Which of the following is NOT a core component of the LangChain framework?\n",
      "\n",
      "a) `langchain-core`\n",
      "b) `langchain-community`\n",
      "c) `langchain-blockchain` \n",
      "d) LangGraph\n",
      "\n",
      "**Answer: c)**\n",
      "\n",
      "**Question 3**\n",
      "\n",
      "What is the purpose of LangSmith in the LangChain ecosystem?\n",
      "\n",
      "a) To build blockchain-based applications using LLMs.\n",
      "b) To deploy LangChain chains as REST APIs.\n",
      "c) To inspect, monitor, and evaluate LLM applications for optimization and deployment. \n",
      "d) To provide a library of pre-trained LLM models for various tasks.\n",
      "\n",
      "**Answer: c)**\n",
      "\n",
      "**Question 4**\n",
      "\n",
      "Where can developers find concise instructions for accomplishing common tasks using LangChain?\n",
      "\n",
      "a) In the \"Tutorials\" section of the documentation.\n",
      "b) In the \"How-to guides\" section of the documentation. \n",
      "c) In the \"Conceptual guide\" section of the documentation.\n",
      "d) In the \"API reference\" section of the documentation.\n",
      "\n",
      "**Answer: b)**\n",
      "\n",
      "**Question 5**\n",
      "\n",
      "What is LangGraph primarily used for?\n",
      "\n",
      "a) Building and managing knowledge graphs from unstructured data.\n",
      "b) Creating and deploying serverless functions for LLM applications.\n",
      "c) Building stateful, multi-actor applications with LLMs. \n",
      "d) Training and fine-tuning LLM models on custom datasets.\n",
      "\n",
      "**Answer: c)** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "quiz_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Generate {num_questions} quiz questions with four multiple-choice options for each question. Highlight the correct answer.\"),\n",
    "        (\"human\", \"You have to following the below content to create the quizes\\n \\\n",
    "         Content: {text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "Chain = quiz_prompt | llm | StrOutputParser()\n",
    "result = Chain.invoke({\"num_questions\":\"5\", \"text\":text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
